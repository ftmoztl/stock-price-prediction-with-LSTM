{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MbAB4Lk9hn-f","executionInfo":{"status":"ok","timestamp":1672563180358,"user_tz":-180,"elapsed":19744,"user":{"displayName":"Fatma Oztel","userId":"09453375312460641726"}},"outputId":"b6a35860-3e62-4970-9b4f-17831bb3ff9a"},"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[K     |████████████████████████████████| 1.9 MB 3.8 MB/s \n","\u001b[K     |████████████████████████████████| 184 kB 90.6 MB/s \n","\u001b[K     |████████████████████████████████| 174 kB 5.1 MB/s \n","\u001b[K     |████████████████████████████████| 62 kB 1.4 MB/s \n","\u001b[K     |████████████████████████████████| 173 kB 79.6 MB/s \n","\u001b[K     |████████████████████████████████| 168 kB 73.4 MB/s \n","\u001b[K     |████████████████████████████████| 168 kB 70.2 MB/s \n","\u001b[K     |████████████████████████████████| 166 kB 52.1 MB/s \n","\u001b[K     |████████████████████████████████| 166 kB 85.4 MB/s \n","\u001b[K     |████████████████████████████████| 162 kB 68.1 MB/s \n","\u001b[K     |████████████████████████████████| 162 kB 69.1 MB/s \n","\u001b[K     |████████████████████████████████| 158 kB 66.6 MB/s \n","\u001b[K     |████████████████████████████████| 157 kB 86.1 MB/s \n","\u001b[K     |████████████████████████████████| 157 kB 60.5 MB/s \n","\u001b[K     |████████████████████████████████| 157 kB 40.0 MB/s \n","\u001b[K     |████████████████████████████████| 157 kB 79.1 MB/s \n","\u001b[K     |████████████████████████████████| 157 kB 86.7 MB/s \n","\u001b[K     |████████████████████████████████| 157 kB 81.1 MB/s \n","\u001b[K     |████████████████████████████████| 157 kB 61.4 MB/s \n","\u001b[K     |████████████████████████████████| 156 kB 81.9 MB/s \n","\u001b[?25h  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Reading package lists... Done\n","Building dependency tree       \n","Reading state information... Done\n","The following package was automatically installed and is no longer required:\n","  libnvidia-common-460\n","Use 'apt autoremove' to remove it.\n","The following NEW packages will be installed:\n","  tree\n","0 upgraded, 1 newly installed, 0 to remove and 20 not upgraded.\n","Need to get 40.7 kB of archives.\n","After this operation, 105 kB of additional disk space will be used.\n","Get:1 http://archive.ubuntu.com/ubuntu bionic/universe amd64 tree amd64 1.7.0-5 [40.7 kB]\n","Fetched 40.7 kB in 1s (62.1 kB/s)\n","Selecting previously unselected package tree.\n","(Reading database ... 124016 files and directories currently installed.)\n","Preparing to unpack .../tree_1.7.0-5_amd64.deb ...\n","Unpacking tree (1.7.0-5) ...\n","Setting up tree (1.7.0-5) ...\n","Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n"]}],"source":["!pip install wandb -qqq\n","!apt install tree"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cCpwmCzq96Nr"},"outputs":[],"source":["# !wandb login --relogin"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":108},"executionInfo":{"elapsed":10183,"status":"ok","timestamp":1672563331809,"user":{"displayName":"Fatma Oztel","userId":"09453375312460641726"},"user_tz":-180},"id":"pUSHmzGGgnq_","outputId":"9a4ac7ed-209e-4c44-96b8-dea52cd435ae"},"outputs":[{"output_type":"stream","name":"stderr","text":["ERROR:wandb.jupyter:Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["\n","        window._wandbApiKey = new Promise((resolve, reject) => {\n","            function loadScript(url) {\n","            return new Promise(function(resolve, reject) {\n","                let newScript = document.createElement(\"script\");\n","                newScript.onerror = reject;\n","                newScript.onload = resolve;\n","                document.body.appendChild(newScript);\n","                newScript.src = url;\n","            });\n","            }\n","            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n","            const iframe = document.createElement('iframe')\n","            iframe.style.cssText = \"width:0;height:0;border:none\"\n","            document.body.appendChild(iframe)\n","            const handshake = new Postmate({\n","                container: iframe,\n","                url: 'https://wandb.ai/authorize'\n","            });\n","            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n","            handshake.then(function(child) {\n","                child.on('authorize', data => {\n","                    clearTimeout(timeout)\n","                    resolve(data)\n","                });\n","            });\n","            })\n","        });\n","    "]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"]},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":3}],"source":["import wandb\n","wandb.login()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NdD96olUhYV3"},"outputs":[],"source":["import random\n","import torch\n","import torchvision\n","from torch.utils.data import TensorDataset\n","from tqdm.auto import tqdm\n","import pandas as pd\n","import numpy as np\n","from torch.autograd import Variable\n","from sklearn.preprocessing import MinMaxScaler\n","import torch\n","import torch.nn as nn\n","from sklearn.preprocessing import StandardScaler\n","from math import sqrt\n","import math, time\n","from sklearn.metrics import mean_squared_error,mean_absolute_percentage_error\n","from torch.utils.data import DataLoader\n","\n","from itertools import cycle\n","import plotly.graph_objects as go\n","import plotly.express as px\n","from plotly.subplots import make_subplots"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":26467,"status":"ok","timestamp":1672563503399,"user":{"displayName":"Fatma Oztel","userId":"09453375312460641726"},"user_tz":-180},"id":"57PynzXjjflC","outputId":"beb356c5-e744-4e4d-ea32-c3b44fad8bce"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/gdrive\n"]}],"source":["#this block was only used to connect the google drive for colab implementations\n","#if you're working on your local, please skip this part\n","\n","from google.colab import drive\n","drive.mount('/content/gdrive')"]},{"cell_type":"code","source":["#please add sys path to reach the modules of the functions\n","\n","import sys\n","sys.path.append('/content/gdrive/MyDrive/Colab Notebooks/DataCraft_notebook/Code files/One py for each application/')"],"metadata":{"id":"VG5z87WHyqaz"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## FUNCTIONS"],"metadata":{"id":"R73SoNGECjCr"}},{"cell_type":"code","source":["#import cerated early stopping, LSTM model and sequence functions in py files\n","\n","from earlyStopping import EarlyStopping\n","from LSTM_model import LSTM\n","from sequenceDataset import SequenceDataset"],"metadata":{"id":"nx4PrGnfysN6"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3ALtrrusrhHj"},"outputs":[],"source":["def split(df, SeqLen): #splitdataset\n","  split = [int(len(df)*0.8), int(len(df)*0.9)] #give split index for train, valid, test\n","  train = df[:split[0]]  #~%80\n","  val = df[split[0]-SeqLen:split[1]] # ~%10\n","  test = df[split[1]-SeqLen:]  # ~%10\n","  return train, val, test"]},{"cell_type":"code","source":["#create evaluation function to get the MAPE and MSE scores of the train, test, validation dataset\n","\n","def evaluation(split,scaled,Steps,model,loader,criterion,scaler):\n","  #calculate test loss, MSE and MAPE   \n","  loss=0    \n","  y_pred = torch.tensor([]).cuda()\n","  y=torch.tensor([]).cuda()\n","  y=torch.reshape(y, (-1,))\n","  y_pred=torch.reshape(y_pred, (-1,))\n","  model.eval()\n","  with torch.no_grad():\n","      for X, Y in loader:\n","          X=X.cuda()\n","          Y=Y.cuda()\n","          y = torch.cat((y, Y), 0)\n","          predict = model(X)\n","          \n","          predict=torch.reshape(predict, (-1,))\n","          y_pred = torch.cat((y_pred.cuda(), predict), 0)\n","          loss += criterion(y_pred, y).item()\n","\n","  avg_loss = loss / Steps\n","  print(\"{} loss:\".format(split),avg_loss)\n","\n","  #reshape, concatenate, and apply inverse scaler transform to calculate the error values\n","  scaled_open=np.reshape(scaled[:,1], (-1,1))\n","  y_pred=np.reshape(y_pred.cpu().detach().numpy(), (-1,1))\n","  pred_open=np.concatenate((y_pred, scaled_open), axis=1)\n","  pred_open = scaler.inverse_transform(pred_open)\n","  price_open=np.concatenate((np.reshape(y.cpu().detach().numpy(), (-1,1)), scaled_open), axis=1)\n","  price_open = scaler.inverse_transform(price_open)\n","\n","  mse_score = mean_squared_error(price_open[:,0], pred_open[:,0])\n","  print(split+' MSE: %.2f MSE' % (mse_score))\n","\n","  mape_score = mean_absolute_percentage_error(price_open[:,0], pred_open[:,0])\n","  print(split+\" MAPE:\",mape_score)\n","\n","  return (mape_score,mse_score)\n"],"metadata":{"id":"C3bXh3vJ2I3v"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## DATASET"],"metadata":{"id":"dCJlIYxvWC-y"}},{"cell_type":"markdown","source":["The code user should indicate which dataset will be processed in this notebook. Because there are 3 different datasets belonging to the 3 different companies. These include the stock prices of Apple, Samsung, and Xiaomi companies."],"metadata":{"id":"FphucXl4V8K0"}},{"cell_type":"code","source":["#initialize the variable\n","company = \"Apple\""],"metadata":{"id":"GdRMhp7gWsoY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#get the datset\n","with wandb.init(project=\"DSS\") as r:\n","         \n","        # ✔️ declare which artifact we'll be using\n","        if company == 'Apple':\n","          artifact = r.use_artifact('metu_datacraft/DSS/Apple:v2', type='Data')\n","        elif company == 'Samsung':\n","          artifact = r.use_artifact('metu_datacraft/DSS/Samsung:v2', type='Data')\n","        elif company == 'Xiaomi':\n","          artifact = r.use_artifact('metu_datacraft/DSS/Xiaomi:v2', type='Data')\n","        else:\n","          raise Exception(\"Sorry, please enter the company name correctly\")\n","\n","        table = artifact.get('weekday_data')\n","        dataset= {\"Date\": table.get_column(\"Date\"),\"Price\":table.get_column(\"Price\"),\"Open\":table.get_column(\"Open\"),\n","                  \"High\":table.get_column(\"High\"), \"Low\":table.get_column(\"Low\") , \"Volume\": table.get_column(\"Volume\"),\n","                  \"Change\":table.get_column(\"Change\")}\n","        data = pd.DataFrame(dataset)"],"metadata":{"id":"c7RiNccdWwcJ","colab":{"base_uri":"https://localhost:8080/","height":239,"referenced_widgets":["0fd47f2350e749c9b8336ae897803422","d73501f8fa6a4e7a8e9b7f621abc4955","0e562459a15a40e0b8e04cc3f7f2ce8b","d8410f4020c44c9f865933f6c1b63781","5d4ac5f051ee432ba83dc02caa251163","65b39886253449fd807aef694ff85f4e","435b41d51eb04aba83086d0de3cca116","0afb8d6bf21a4f69b8070984b0e1b437"]},"executionInfo":{"status":"ok","timestamp":1672563577583,"user_tz":-180,"elapsed":10532,"user":{"displayName":"Fatma Oztel","userId":"09453375312460641726"}},"outputId":"ee3a0f4b-8b74-42fc-ecd4-41cc53d0de4e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mfatmaoztel\u001b[0m (\u001b[33mmetu_datacraft\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Tracking run with wandb version 0.13.7"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Run data is saved locally in <code>/content/wandb/run-20230101_085926-24nxd0m8</code>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Syncing run <strong><a href=\"https://wandb.ai/metu_datacraft/DSS/runs/24nxd0m8\" target=\"_blank\">breezy-glitter-3430</a></strong> to <a href=\"https://wandb.ai/metu_datacraft/DSS\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mwandb\u001b[0m:   1 of 1 files downloaded.  \n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0fd47f2350e749c9b8336ae897803422"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Synced <strong style=\"color:#cdcd00\">breezy-glitter-3430</strong>: <a href=\"https://wandb.ai/metu_datacraft/DSS/runs/24nxd0m8\" target=\"_blank\">https://wandb.ai/metu_datacraft/DSS/runs/24nxd0m8</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Find logs at: <code>./wandb/run-20230101_085926-24nxd0m8/logs</code>"]},"metadata":{}}]},{"cell_type":"markdown","source":["For only Apple dataset, the dataset had to be filtered to get high performance on the model prediction. This filtering issue was not applied on the other datasets belong to Samsung and Xiaomi. "],"metadata":{"id":"Am8MPC4NX-2W"}},{"cell_type":"code","source":["#the data was filtered to get the values of stock prices after the year 2020 to get more powerful model\n","#this block is valid only for Apple dataset\n","if company == 'Apple':\n","  data['Date'] = pd.to_datetime(data.Date)\n","  data = data[data['Date']>'2020-01-01']\n","  data.reset_index(inplace=True)\n","  data.drop(columns={'index'},inplace=True)"],"metadata":{"id":"DQrPCxo5X6VR"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"LXAJSmiTreq4"},"source":["## HYPERPARAMETER TUNING FOR ARCHITECTURE"]},{"cell_type":"markdown","source":["In this section, the LSTM model was used as the main model. Firstly hyperparameter tuning was applied only to determine the number of hidden layers and nodes. The aim of this tuning was to create an architecture of the LSTM model.\n"],"metadata":{"id":"wGkyGQt7Rqd3"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"IjCYiOh4rhHi"},"outputs":[],"source":["DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uGo0swv0r8BK"},"outputs":[],"source":["#create sweep config for the architecture tuning\n","#only use number of layer and node to tune\n","sweep_config = {\n","    'method': 'bayes',\n","\n","    'metric': {\n","      'name': 'average_train_loss',\n","      'goal': 'minimize'   \n","    },\n","    'metric': {\n","      'name': 'average_valid_loss',\n","      'goal': 'minimize'   \n","    },\n","    \"parameters\" : {'hidden_dim': {'values': [1,2,4,8,16,32]},                      \n","                            'num_layers':{'values':[1,2,3]}\n","                    }\n","                }"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":793,"status":"ok","timestamp":1672563589946,"user":{"displayName":"Fatma Oztel","userId":"09453375312460641726"},"user_tz":-180},"id":"oxNO_a_arhHi","outputId":"7e2853fe-b1f6-4fee-8f2a-288e7cfda914"},"outputs":[{"output_type":"stream","name":"stdout","text":["Create sweep with ID: yg2h3a3u\n","Sweep URL: https://wandb.ai/metu_datacraft/DSS/sweeps/yg2h3a3u\n"]}],"source":["#create sweep id\n","sweep_id = wandb.sweep(sweep_config, project=\"DSS\", entity=\"metu_datacraft\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bX-Z7mQxrhHi"},"outputs":[],"source":["#give constant parameters for this architecture tuning\n","#they keep same to tune the number of layer and node\n","input_dim = 1\n","output_dim = 1\n","batch_size=5\n","n_epochs=500000\n","sequence_length=90"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":113232,"status":"ok","timestamp":1672564024845,"user":{"displayName":"Fatma Oztel","userId":"09453375312460641726"},"user_tz":-180},"id":"P1735CwNrhHj","outputId":"ac47f803-5391-40e7-a906-ad4b2872e975"},"outputs":[{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: mji8gucd with config:\n","\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_dim: 16\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_layers: 3\n","Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Tracking run with wandb version 0.13.7"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Run data is saved locally in <code>/content/wandb/run-20230101_090516-mji8gucd</code>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Syncing run <strong><a href=\"https://wandb.ai/metu_datacraft/DSS/runs/mji8gucd\" target=\"_blank\">rural-sweep-5</a></strong> to <a href=\"https://wandb.ai/metu_datacraft/DSS\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/metu_datacraft/DSS/sweeps/yg2h3a3u\" target=\"_blank\">https://wandb.ai/metu_datacraft/DSS/sweeps/yg2h3a3u</a>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Epoch: 0, Train loss: 0.71667, Valid loss: 0.4562659\n","Epoch: 1, Train loss: 0.10711, Valid loss: 0.0656169\n","Epoch: 2, Train loss: 0.03167, Valid loss: 0.0619145\n","Epoch: 3, Train loss: 0.02636, Valid loss: 0.0528179\n","Epoch: 4, Train loss: 0.02395, Valid loss: 0.0493903\n","Epoch: 5, Train loss: 0.02253, Valid loss: 0.0504269\n","EarlyStopping counter: 1 out of 10\n","Epoch: 6, Train loss: 0.02069, Valid loss: 0.0539201\n","EarlyStopping counter: 2 out of 10\n","Epoch: 7, Train loss: 0.02034, Valid loss: 0.0408695\n","Epoch: 8, Train loss: 0.01798, Valid loss: 0.0486060\n","EarlyStopping counter: 1 out of 10\n","Epoch: 9, Train loss: 0.01685, Valid loss: 0.0367022\n","Epoch: 10, Train loss: 0.01676, Valid loss: 0.0305128\n","Epoch: 11, Train loss: 0.01530, Valid loss: 0.0307054\n","EarlyStopping counter: 1 out of 10\n","Epoch: 12, Train loss: 0.01433, Valid loss: 0.0271757\n","Epoch: 13, Train loss: 0.01296, Valid loss: 0.0236253\n","Epoch: 14, Train loss: 0.01186, Valid loss: 0.0226268\n","Epoch: 15, Train loss: 0.01197, Valid loss: 0.0200558\n","Epoch: 16, Train loss: 0.01147, Valid loss: 0.0220546\n","EarlyStopping counter: 1 out of 10\n","Epoch: 17, Train loss: 0.01010, Valid loss: 0.0171444\n","Epoch: 18, Train loss: 0.01006, Valid loss: 0.0144827\n","Epoch: 19, Train loss: 0.00838, Valid loss: 0.0141144\n","Epoch: 20, Train loss: 0.00834, Valid loss: 0.0184170\n","EarlyStopping counter: 1 out of 10\n","Epoch: 21, Train loss: 0.00824, Valid loss: 0.0121052\n","Epoch: 22, Train loss: 0.00754, Valid loss: 0.0128656\n","EarlyStopping counter: 1 out of 10\n","Epoch: 23, Train loss: 0.00704, Valid loss: 0.0138014\n","EarlyStopping counter: 2 out of 10\n","Epoch: 24, Train loss: 0.00744, Valid loss: 0.0106923\n","Epoch: 25, Train loss: 0.00595, Valid loss: 0.0100920\n","Epoch: 26, Train loss: 0.00584, Valid loss: 0.0103240\n","EarlyStopping counter: 1 out of 10\n","Epoch: 27, Train loss: 0.00611, Valid loss: 0.0190087\n","EarlyStopping counter: 2 out of 10\n","Epoch: 28, Train loss: 0.00737, Valid loss: 0.0098987\n","Epoch: 29, Train loss: 0.00557, Valid loss: 0.0134992\n","EarlyStopping counter: 1 out of 10\n","Epoch: 30, Train loss: 0.00521, Valid loss: 0.0094801\n","Epoch: 31, Train loss: 0.00597, Valid loss: 0.0090479\n","Epoch: 32, Train loss: 0.00534, Valid loss: 0.0107056\n","EarlyStopping counter: 1 out of 10\n","Epoch: 33, Train loss: 0.00514, Valid loss: 0.0091653\n","EarlyStopping counter: 2 out of 10\n","Epoch: 34, Train loss: 0.00504, Valid loss: 0.0159866\n","EarlyStopping counter: 3 out of 10\n","Epoch: 35, Train loss: 0.00520, Valid loss: 0.0089134\n","Epoch: 36, Train loss: 0.00500, Valid loss: 0.0092033\n","EarlyStopping counter: 1 out of 10\n","Epoch: 37, Train loss: 0.00472, Valid loss: 0.0124472\n","EarlyStopping counter: 2 out of 10\n","Epoch: 38, Train loss: 0.00502, Valid loss: 0.0089068\n","EarlyStopping counter: 3 out of 10\n","Epoch: 39, Train loss: 0.00511, Valid loss: 0.0117830\n","EarlyStopping counter: 4 out of 10\n","Epoch: 40, Train loss: 0.00471, Valid loss: 0.0093547\n","EarlyStopping counter: 5 out of 10\n","Epoch: 41, Train loss: 0.00468, Valid loss: 0.0111023\n","EarlyStopping counter: 6 out of 10\n","Epoch: 42, Train loss: 0.00475, Valid loss: 0.0143726\n","EarlyStopping counter: 7 out of 10\n","Epoch: 43, Train loss: 0.00579, Valid loss: 0.0111425\n","EarlyStopping counter: 8 out of 10\n","Epoch: 44, Train loss: 0.00456, Valid loss: 0.0088791\n","EarlyStopping counter: 9 out of 10\n","Epoch: 45, Train loss: 0.00511, Valid loss: 0.0148635\n","EarlyStopping counter: 10 out of 10\n","Early stopping at epoch:  45\n","Test loss: 0.01541656130575575\n","Test MSE: 14.13 MSE\n","Test MAPE: 0.020383796166930705\n","Train loss: 0.015416564070619643\n","Train MSE: 14.13 MSE\n","Train MAPE: 0.02038379689647373\n","Valid loss: 0.015416562091559172\n","Valid MSE: 14.13 MSE\n","Valid MAPE: 0.02038379613388178\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["<style>\n","    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n","    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n","    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n","    </style>\n","<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇████</td></tr><tr><td>average_train_loss</td><td>█▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>average_valid_loss</td><td>█▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>mape_test_score</td><td>▁</td></tr><tr><td>mape_train_score</td><td>▁</td></tr><tr><td>mse_test_score</td><td>▁</td></tr><tr><td>mse_train_score</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Epoch</td><td>45</td></tr><tr><td>average_train_loss</td><td>0.00511</td></tr><tr><td>average_valid_loss</td><td>0.01486</td></tr><tr><td>mape_test_score</td><td>0.02038</td></tr><tr><td>mape_train_score</td><td>0.02038</td></tr><tr><td>mse_test_score</td><td>14.12791</td></tr><tr><td>mse_train_score</td><td>14.12792</td></tr></table><br/></div></div>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Synced <strong style=\"color:#cdcd00\">rural-sweep-5</strong>: <a href=\"https://wandb.ai/metu_datacraft/DSS/runs/mji8gucd\" target=\"_blank\">https://wandb.ai/metu_datacraft/DSS/runs/mji8gucd</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Find logs at: <code>./wandb/run-20230101_090516-mji8gucd/logs</code>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: jafemb72 with config:\n","\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_dim: 16\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_layers: 3\n","Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Tracking run with wandb version 0.13.7"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Run data is saved locally in <code>/content/wandb/run-20230101_090552-jafemb72</code>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Syncing run <strong><a href=\"https://wandb.ai/metu_datacraft/DSS/runs/jafemb72\" target=\"_blank\">usual-sweep-6</a></strong> to <a href=\"https://wandb.ai/metu_datacraft/DSS\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/metu_datacraft/DSS/sweeps/yg2h3a3u\" target=\"_blank\">https://wandb.ai/metu_datacraft/DSS/sweeps/yg2h3a3u</a>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Epoch: 0, Train loss: 0.46118, Valid loss: 0.0899807\n","Epoch: 1, Train loss: 0.02951, Valid loss: 0.0617130\n","Epoch: 2, Train loss: 0.02190, Valid loss: 0.0476692\n","Epoch: 3, Train loss: 0.02101, Valid loss: 0.0459809\n","Epoch: 4, Train loss: 0.02085, Valid loss: 0.0437799\n","Epoch: 5, Train loss: 0.01783, Valid loss: 0.0428992\n","Epoch: 6, Train loss: 0.01637, Valid loss: 0.0368571\n","Epoch: 7, Train loss: 0.01511, Valid loss: 0.0382934\n","EarlyStopping counter: 1 out of 10\n","Epoch: 8, Train loss: 0.01521, Valid loss: 0.0311883\n","Epoch: 9, Train loss: 0.01391, Valid loss: 0.0295331\n","Epoch: 10, Train loss: 0.01411, Valid loss: 0.0253140\n","Epoch: 11, Train loss: 0.01252, Valid loss: 0.0273580\n","EarlyStopping counter: 1 out of 10\n","Epoch: 12, Train loss: 0.01220, Valid loss: 0.0223158\n","Epoch: 13, Train loss: 0.01063, Valid loss: 0.0205643\n","Epoch: 14, Train loss: 0.01016, Valid loss: 0.0186271\n","Epoch: 15, Train loss: 0.01027, Valid loss: 0.0205353\n","EarlyStopping counter: 1 out of 10\n","Epoch: 16, Train loss: 0.00952, Valid loss: 0.0163511\n","Epoch: 17, Train loss: 0.00877, Valid loss: 0.0156014\n","Epoch: 18, Train loss: 0.00835, Valid loss: 0.0151897\n","Epoch: 19, Train loss: 0.00851, Valid loss: 0.0140394\n","Epoch: 20, Train loss: 0.00740, Valid loss: 0.0123273\n","Epoch: 21, Train loss: 0.00671, Valid loss: 0.0135944\n","EarlyStopping counter: 1 out of 10\n","Epoch: 22, Train loss: 0.00689, Valid loss: 0.0118935\n","Epoch: 23, Train loss: 0.00655, Valid loss: 0.0120274\n","EarlyStopping counter: 1 out of 10\n","Epoch: 24, Train loss: 0.00673, Valid loss: 0.0126733\n","EarlyStopping counter: 2 out of 10\n","Epoch: 25, Train loss: 0.00589, Valid loss: 0.0139048\n","EarlyStopping counter: 3 out of 10\n","Epoch: 26, Train loss: 0.00651, Valid loss: 0.0100623\n","Epoch: 27, Train loss: 0.00560, Valid loss: 0.0152187\n","EarlyStopping counter: 1 out of 10\n","Epoch: 28, Train loss: 0.00560, Valid loss: 0.0092532\n","Epoch: 29, Train loss: 0.00505, Valid loss: 0.0100602\n","EarlyStopping counter: 1 out of 10\n","Epoch: 30, Train loss: 0.00553, Valid loss: 0.0103574\n","EarlyStopping counter: 2 out of 10\n","Epoch: 31, Train loss: 0.00520, Valid loss: 0.0106782\n","EarlyStopping counter: 3 out of 10\n","Epoch: 32, Train loss: 0.00575, Valid loss: 0.0092976\n","EarlyStopping counter: 4 out of 10\n","Epoch: 33, Train loss: 0.00506, Valid loss: 0.0089370\n","Epoch: 34, Train loss: 0.00491, Valid loss: 0.0104464\n","EarlyStopping counter: 1 out of 10\n","Epoch: 35, Train loss: 0.00505, Valid loss: 0.0109561\n","EarlyStopping counter: 2 out of 10\n","Epoch: 36, Train loss: 0.00471, Valid loss: 0.0118740\n","EarlyStopping counter: 3 out of 10\n","Epoch: 37, Train loss: 0.00460, Valid loss: 0.0089490\n","EarlyStopping counter: 4 out of 10\n","Epoch: 38, Train loss: 0.00441, Valid loss: 0.0096931\n","EarlyStopping counter: 5 out of 10\n","Epoch: 39, Train loss: 0.00506, Valid loss: 0.0105793\n","EarlyStopping counter: 6 out of 10\n","Epoch: 40, Train loss: 0.00476, Valid loss: 0.0094595\n","EarlyStopping counter: 7 out of 10\n","Epoch: 41, Train loss: 0.00507, Valid loss: 0.0086929\n","Epoch: 42, Train loss: 0.00465, Valid loss: 0.0091805\n","EarlyStopping counter: 1 out of 10\n","Epoch: 43, Train loss: 0.00486, Valid loss: 0.0127770\n","EarlyStopping counter: 2 out of 10\n","Epoch: 44, Train loss: 0.00455, Valid loss: 0.0095999\n","EarlyStopping counter: 3 out of 10\n","Epoch: 45, Train loss: 0.00583, Valid loss: 0.0089460\n","EarlyStopping counter: 4 out of 10\n","Epoch: 46, Train loss: 0.00482, Valid loss: 0.0102861\n","EarlyStopping counter: 5 out of 10\n","Epoch: 47, Train loss: 0.00476, Valid loss: 0.0096378\n","EarlyStopping counter: 6 out of 10\n","Epoch: 48, Train loss: 0.00478, Valid loss: 0.0090236\n","EarlyStopping counter: 7 out of 10\n","Epoch: 49, Train loss: 0.00503, Valid loss: 0.0090188\n","EarlyStopping counter: 8 out of 10\n","Epoch: 50, Train loss: 0.00471, Valid loss: 0.0100105\n","EarlyStopping counter: 9 out of 10\n","Epoch: 51, Train loss: 0.00487, Valid loss: 0.0089379\n","EarlyStopping counter: 10 out of 10\n","Early stopping at epoch:  51\n","Test loss: 0.008274117470136844\n","Test MSE: 8.83 MSE\n","Test MAPE: 0.015101841376813146\n","Train loss: 0.008274117310065776\n","Train MSE: 8.83 MSE\n","Train MAPE: 0.01510184144502233\n","Valid loss: 0.008274115789390635\n","Valid MSE: 8.83 MSE\n","Valid MAPE: 0.015101840393080128\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["<style>\n","    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n","    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n","    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n","    </style>\n","<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>average_train_loss</td><td>█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>average_valid_loss</td><td>█▆▄▄▄▃▄▃▂▃▂▂▂▂▂▁▁▁▁▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>mape_test_score</td><td>▁</td></tr><tr><td>mape_train_score</td><td>▁</td></tr><tr><td>mse_test_score</td><td>▁</td></tr><tr><td>mse_train_score</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Epoch</td><td>51</td></tr><tr><td>average_train_loss</td><td>0.00487</td></tr><tr><td>average_valid_loss</td><td>0.00894</td></tr><tr><td>mape_test_score</td><td>0.0151</td></tr><tr><td>mape_train_score</td><td>0.0151</td></tr><tr><td>mse_test_score</td><td>8.83465</td></tr><tr><td>mse_train_score</td><td>8.83465</td></tr></table><br/></div></div>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Synced <strong style=\"color:#cdcd00\">usual-sweep-6</strong>: <a href=\"https://wandb.ai/metu_datacraft/DSS/runs/jafemb72\" target=\"_blank\">https://wandb.ai/metu_datacraft/DSS/runs/jafemb72</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Find logs at: <code>./wandb/run-20230101_090552-jafemb72/logs</code>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: w5pv7oet with config:\n","\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_dim: 16\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_layers: 3\n","Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Tracking run with wandb version 0.13.7"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Run data is saved locally in <code>/content/wandb/run-20230101_090633-w5pv7oet</code>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Syncing run <strong><a href=\"https://wandb.ai/metu_datacraft/DSS/runs/w5pv7oet\" target=\"_blank\">scarlet-sweep-7</a></strong> to <a href=\"https://wandb.ai/metu_datacraft/DSS\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/metu_datacraft/DSS/sweeps/yg2h3a3u\" target=\"_blank\">https://wandb.ai/metu_datacraft/DSS/sweeps/yg2h3a3u</a>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Epoch: 0, Train loss: 0.59136, Valid loss: 0.1760133\n","Epoch: 1, Train loss: 0.04718, Valid loss: 0.0933608\n","Epoch: 2, Train loss: 0.02819, Valid loss: 0.0751333\n","Epoch: 3, Train loss: 0.02568, Valid loss: 0.0716542\n","Epoch: 4, Train loss: 0.02370, Valid loss: 0.0536869\n","Epoch: 5, Train loss: 0.02349, Valid loss: 0.0458241\n","Epoch: 6, Train loss: 0.02175, Valid loss: 0.0533330\n","EarlyStopping counter: 1 out of 10\n","Epoch: 7, Train loss: 0.01855, Valid loss: 0.0506147\n","EarlyStopping counter: 2 out of 10\n","Epoch: 8, Train loss: 0.01778, Valid loss: 0.0441791\n","Epoch: 9, Train loss: 0.01534, Valid loss: 0.0343096\n","Epoch: 10, Train loss: 0.01615, Valid loss: 0.0332069\n","Epoch: 11, Train loss: 0.01356, Valid loss: 0.0274431\n","Epoch: 12, Train loss: 0.01352, Valid loss: 0.0308539\n","EarlyStopping counter: 1 out of 10\n","Epoch: 13, Train loss: 0.01255, Valid loss: 0.0354975\n","EarlyStopping counter: 2 out of 10\n","Epoch: 14, Train loss: 0.01140, Valid loss: 0.0189282\n","Epoch: 15, Train loss: 0.00995, Valid loss: 0.0175041\n","Epoch: 16, Train loss: 0.01011, Valid loss: 0.0163038\n","Epoch: 17, Train loss: 0.00915, Valid loss: 0.0155877\n","Epoch: 18, Train loss: 0.00875, Valid loss: 0.0165109\n","EarlyStopping counter: 1 out of 10\n","Epoch: 19, Train loss: 0.00773, Valid loss: 0.0214118\n","EarlyStopping counter: 2 out of 10\n","Epoch: 20, Train loss: 0.00724, Valid loss: 0.0129673\n","Epoch: 21, Train loss: 0.00744, Valid loss: 0.0115434\n","Epoch: 22, Train loss: 0.00699, Valid loss: 0.0111774\n","Epoch: 23, Train loss: 0.00695, Valid loss: 0.0129515\n","EarlyStopping counter: 1 out of 10\n","Epoch: 24, Train loss: 0.00664, Valid loss: 0.0110956\n","EarlyStopping counter: 2 out of 10\n","Epoch: 25, Train loss: 0.00630, Valid loss: 0.0113881\n","EarlyStopping counter: 3 out of 10\n","Epoch: 26, Train loss: 0.00564, Valid loss: 0.0095131\n","Epoch: 27, Train loss: 0.00558, Valid loss: 0.0096062\n","EarlyStopping counter: 1 out of 10\n","Epoch: 28, Train loss: 0.00554, Valid loss: 0.0092376\n","Epoch: 29, Train loss: 0.00529, Valid loss: 0.0089479\n","Epoch: 30, Train loss: 0.00534, Valid loss: 0.0092943\n","EarlyStopping counter: 1 out of 10\n","Epoch: 31, Train loss: 0.00537, Valid loss: 0.0113489\n","EarlyStopping counter: 2 out of 10\n","Epoch: 32, Train loss: 0.00492, Valid loss: 0.0086854\n","Epoch: 33, Train loss: 0.00508, Valid loss: 0.0095686\n","EarlyStopping counter: 1 out of 10\n","Epoch: 34, Train loss: 0.00501, Valid loss: 0.0116771\n","EarlyStopping counter: 2 out of 10\n","Epoch: 35, Train loss: 0.00496, Valid loss: 0.0089495\n","EarlyStopping counter: 3 out of 10\n","Epoch: 36, Train loss: 0.00499, Valid loss: 0.0086278\n","EarlyStopping counter: 4 out of 10\n","Epoch: 37, Train loss: 0.00617, Valid loss: 0.0087934\n","EarlyStopping counter: 5 out of 10\n","Epoch: 38, Train loss: 0.00471, Valid loss: 0.0096938\n","EarlyStopping counter: 6 out of 10\n","Epoch: 39, Train loss: 0.00551, Valid loss: 0.0103258\n","EarlyStopping counter: 7 out of 10\n","Epoch: 40, Train loss: 0.00468, Valid loss: 0.0130483\n","EarlyStopping counter: 8 out of 10\n","Epoch: 41, Train loss: 0.00517, Valid loss: 0.0087997\n","EarlyStopping counter: 9 out of 10\n","Epoch: 42, Train loss: 0.00461, Valid loss: 0.0104484\n","EarlyStopping counter: 10 out of 10\n","Early stopping at epoch:  42\n","Test loss: 0.009222723461789428\n","Test MSE: 9.97 MSE\n","Test MAPE: 0.01607558866193196\n","Train loss: 0.009222723096172558\n","Train MSE: 9.97 MSE\n","Train MAPE: 0.016075589470141264\n","Valid loss: 0.009222724238497904\n","Valid MSE: 9.97 MSE\n","Valid MAPE: 0.01607558938332216\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["<style>\n","    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n","    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n","    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n","    </style>\n","<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇▇██</td></tr><tr><td>average_train_loss</td><td>█▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>average_valid_loss</td><td>█▅▄▄▃▃▃▃▂▂▂▂▂▁▁▁▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>mape_test_score</td><td>▁</td></tr><tr><td>mape_train_score</td><td>▁</td></tr><tr><td>mse_test_score</td><td>▁</td></tr><tr><td>mse_train_score</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Epoch</td><td>42</td></tr><tr><td>average_train_loss</td><td>0.00461</td></tr><tr><td>average_valid_loss</td><td>0.01045</td></tr><tr><td>mape_test_score</td><td>0.01608</td></tr><tr><td>mape_train_score</td><td>0.01608</td></tr><tr><td>mse_test_score</td><td>9.96825</td></tr><tr><td>mse_train_score</td><td>9.96825</td></tr></table><br/></div></div>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Synced <strong style=\"color:#cdcd00\">scarlet-sweep-7</strong>: <a href=\"https://wandb.ai/metu_datacraft/DSS/runs/w5pv7oet\" target=\"_blank\">https://wandb.ai/metu_datacraft/DSS/runs/w5pv7oet</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Find logs at: <code>./wandb/run-20230101_090633-w5pv7oet/logs</code>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 31y1pusa with config:\n","\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_dim: 4\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_layers: 1\n","\u001b[34m\u001b[1mwandb\u001b[0m: Ctrl + C detected. Stopping sweep.\n"]}],"source":["def train(config=None):\n","  with wandb.init(config=config):\n","    config = wandb.config\n","\n","    data['Date'] = pd.to_datetime(data.Date)\n","\n","    #split dataset\n","    train, valid, test = split(data[[\"Price\",\"Open\"]],sequence_length)\n","\n","    #scale the colums and values\n","    scaler = StandardScaler()\n","    train_scaled = scaler.fit_transform(train) #fit the scaler by using train dataset\n","    test_scaled = scaler.transform(test) #scale the test dataset\n","    valid_scaled = scaler.transform(valid) #scale the validation daatset\n","\n","    train_data = pd.DataFrame(train_scaled, columns = ['Price','Open'])\n","    test_data = pd.DataFrame(test_scaled, columns = ['Price','Open'])\n","    valid_data = pd.DataFrame(valid_scaled, columns = ['Price','Open'])\n","\n","    #get sequences of the dataset\n","    train_dataset = SequenceDataset(\n","        train_data,\n","        target=\"Price\",\n","        features=[\"Open\"],\n","        sequence_length=sequence_length\n","    )\n","\n","\n","    test_dataset = SequenceDataset(\n","        test_data,\n","        target=\"Price\",\n","        features=[\"Open\"],\n","        sequence_length=sequence_length\n","    )\n","\n","    valid_dataset = SequenceDataset(\n","        valid_data,\n","        target=\"Price\",\n","        features=[\"Open\"],\n","        sequence_length=sequence_length\n","    )\n","\n","    #create the dataloader for the dataset to create batches\n","    trainloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n","    testloader = DataLoader(test_dataset,batch_size=batch_size,shuffle=False)\n","    validloader = DataLoader(valid_dataset,batch_size=batch_size,shuffle=False)\n","\n","    #call model\n","    model = LSTM(input_dim=input_dim, hidden_dim=config.hidden_dim, num_layers=config.num_layers,output_dim=output_dim).to(DEVICE)\n","\n","    criterion = torch.nn.MSELoss()    # define criterion for loss: mean-squared error \n","    optimizer = torch.optim.AdamW(model.parameters()) #with default learning rate\n","\n","    #use early stopping for tuning\n","    early_stopping = EarlyStopping(patience=10, delta=0.0001, verbose=False)\n","\n","    #keep steps to calculate average loss values\n","    trainSteps = len(train_dataset) //batch_size\n","    testSteps = len(test_dataset)//batch_size\n","    validSteps = len(valid_dataset)//batch_size\n","    count=0\n","    for epoch in range(n_epochs):\n","      model.train()\n","      train_loss = 0\n","      \n","      for X, y in trainloader:\n","          X=X.to(DEVICE)\n","          y=y.to(DEVICE)\n","          output = model(X)\n","          output=torch.reshape(output, (-1,))\n","          loss = criterion(output, y) #calculate the loss\n","          optimizer.zero_grad()\n","          loss.backward()\n","          optimizer.step()\n","          train_loss += loss.item() #calculate the total loss\n","            \n","      #check the validation loss to measure the training performance\n","      valid_loss=0\n","      model.eval()\n","      with torch.no_grad():\n","          for X, y in validloader:\n","              X=X.to(DEVICE)\n","              y=y.to(DEVICE)\n","              predict = model(X)\n","              predict=torch.reshape(predict, (-1,))\n","              valid_loss += criterion(predict, y).item()\n","              \n","      #calculate the loss values of train and validation        \n","      avg_train_loss = train_loss / trainSteps  \n","      avg_valid_loss = valid_loss / validSteps\n","\n","      print(\"Epoch: %d, Train loss: %1.5f, Valid loss: %1.7f\" % (epoch, avg_train_loss,avg_valid_loss))\n","\n","      #log the loss values to the W&B\n","      wandb.log({\"Epoch\":epoch, \"average_train_loss\": avg_train_loss,\"average_valid_loss\":avg_valid_loss})\n","\n","      early_stopping(avg_valid_loss, model)\n","            \n","      if early_stopping.early_stop:\n","          print(\"Early stopping at epoch: \", epoch)\n","          break\n","\n","    mape_test,mse_test=evaluation(\"Test\",test_scaled,testSteps,model,testloader,criterion,scaler)\n","    mape_train,mse_train=evaluation(\"Train\",train_scaled,testSteps,model,trainloader,criterion,scaler)\n","    mape_valid,mse_valid=evaluation(\"Valid\",valid_scaled,testSteps,model,validloader,criterion,scaler)\n","\n","  \n","    #log the scores\n","    wandb.log({\"mse_test_score\": mse_test, \"mape_test_score\": mape_test,\"mse_train_score\":mse_train,\"mape_train_score\":mape_train})\n","\n","wandb.agent(sweep_id, train)"]}],"metadata":{"accelerator":"GPU","colab":{"machine_shape":"hm","provenance":[]},"gpuClass":"premium","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"0fd47f2350e749c9b8336ae897803422":{"model_module":"@jupyter-widgets/controls","model_name":"VBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"VBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"VBoxView","box_style":"","children":["IPY_MODEL_d73501f8fa6a4e7a8e9b7f621abc4955","IPY_MODEL_0e562459a15a40e0b8e04cc3f7f2ce8b"],"layout":"IPY_MODEL_d8410f4020c44c9f865933f6c1b63781"}},"d73501f8fa6a4e7a8e9b7f621abc4955":{"model_module":"@jupyter-widgets/controls","model_name":"LabelModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"LabelModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"LabelView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5d4ac5f051ee432ba83dc02caa251163","placeholder":"​","style":"IPY_MODEL_65b39886253449fd807aef694ff85f4e","value":"0.001 MB of 0.008 MB uploaded (0.000 MB deduped)\r"}},"0e562459a15a40e0b8e04cc3f7f2ce8b":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_435b41d51eb04aba83086d0de3cca116","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_0afb8d6bf21a4f69b8070984b0e1b437","value":0.08610029768719946}},"d8410f4020c44c9f865933f6c1b63781":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5d4ac5f051ee432ba83dc02caa251163":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"65b39886253449fd807aef694ff85f4e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"435b41d51eb04aba83086d0de3cca116":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0afb8d6bf21a4f69b8070984b0e1b437":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}}}}},"nbformat":4,"nbformat_minor":0}