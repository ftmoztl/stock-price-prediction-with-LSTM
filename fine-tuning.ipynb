{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MbAB4Lk9hn-f","executionInfo":{"status":"ok","timestamp":1672765588860,"user_tz":-180,"elapsed":14419,"user":{"displayName":"Beyza Ecem Erce","userId":"07724844839373940404"}},"outputId":"bb8ca384-db0a-44bd-e81d-ee682a8fff8f"},"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[K     |████████████████████████████████| 1.9 MB 4.7 MB/s \n","\u001b[K     |████████████████████████████████| 174 kB 82.9 MB/s \n","\u001b[K     |████████████████████████████████| 184 kB 79.8 MB/s \n","\u001b[K     |████████████████████████████████| 62 kB 1.8 MB/s \n","\u001b[K     |████████████████████████████████| 173 kB 96.9 MB/s \n","\u001b[K     |████████████████████████████████| 168 kB 92.5 MB/s \n","\u001b[K     |████████████████████████████████| 168 kB 98.6 MB/s \n","\u001b[K     |████████████████████████████████| 166 kB 79.9 MB/s \n","\u001b[K     |████████████████████████████████| 166 kB 96.9 MB/s \n","\u001b[K     |████████████████████████████████| 162 kB 100.7 MB/s \n","\u001b[K     |████████████████████████████████| 162 kB 103.5 MB/s \n","\u001b[K     |████████████████████████████████| 158 kB 93.8 MB/s \n","\u001b[K     |████████████████████████████████| 157 kB 98.0 MB/s \n","\u001b[K     |████████████████████████████████| 157 kB 79.3 MB/s \n","\u001b[K     |████████████████████████████████| 157 kB 75.9 MB/s \n","\u001b[K     |████████████████████████████████| 157 kB 80.0 MB/s \n","\u001b[K     |████████████████████████████████| 157 kB 76.9 MB/s \n","\u001b[K     |████████████████████████████████| 157 kB 98.8 MB/s \n","\u001b[K     |████████████████████████████████| 157 kB 103.8 MB/s \n","\u001b[K     |████████████████████████████████| 156 kB 100.4 MB/s \n","\u001b[?25h  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Reading package lists... Done\n","Building dependency tree       \n","Reading state information... Done\n","The following package was automatically installed and is no longer required:\n","  libnvidia-common-460\n","Use 'apt autoremove' to remove it.\n","The following NEW packages will be installed:\n","  tree\n","0 upgraded, 1 newly installed, 0 to remove and 20 not upgraded.\n","Need to get 40.7 kB of archives.\n","After this operation, 105 kB of additional disk space will be used.\n","Get:1 http://archive.ubuntu.com/ubuntu bionic/universe amd64 tree amd64 1.7.0-5 [40.7 kB]\n","Fetched 40.7 kB in 0s (242 kB/s)\n","Selecting previously unselected package tree.\n","(Reading database ... 124016 files and directories currently installed.)\n","Preparing to unpack .../tree_1.7.0-5_amd64.deb ...\n","Unpacking tree (1.7.0-5) ...\n","Setting up tree (1.7.0-5) ...\n","Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n"]}],"source":["!pip install wandb -qqq\n","!apt install tree"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cCpwmCzq96Nr","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1671380702433,"user_tz":-180,"elapsed":14964,"user":{"displayName":"Fatma Oztel","userId":"09453375312460641726"}},"outputId":"e1872d60-d460-44f6-8a96-925cbbf9dbcf"},"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n","\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n","\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit: \n","\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"]}],"source":["# !wandb login --relogin"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":86},"executionInfo":{"elapsed":6574,"status":"ok","timestamp":1672765595428,"user":{"displayName":"Beyza Ecem Erce","userId":"07724844839373940404"},"user_tz":-180},"id":"pUSHmzGGgnq_","outputId":"7aa1fa65-a33d-4fc4-ff13-f65aee2e003c"},"outputs":[{"output_type":"stream","name":"stderr","text":["ERROR:wandb.jupyter:Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["\n","        window._wandbApiKey = new Promise((resolve, reject) => {\n","            function loadScript(url) {\n","            return new Promise(function(resolve, reject) {\n","                let newScript = document.createElement(\"script\");\n","                newScript.onerror = reject;\n","                newScript.onload = resolve;\n","                document.body.appendChild(newScript);\n","                newScript.src = url;\n","            });\n","            }\n","            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n","            const iframe = document.createElement('iframe')\n","            iframe.style.cssText = \"width:0;height:0;border:none\"\n","            document.body.appendChild(iframe)\n","            const handshake = new Postmate({\n","                container: iframe,\n","                url: 'https://wandb.ai/authorize'\n","            });\n","            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n","            handshake.then(function(child) {\n","                child.on('authorize', data => {\n","                    clearTimeout(timeout)\n","                    resolve(data)\n","                });\n","            });\n","            })\n","        });\n","    "]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"]},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":2}],"source":["import wandb\n","wandb.login()"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"NdD96olUhYV3","executionInfo":{"status":"ok","timestamp":1672765599716,"user_tz":-180,"elapsed":4291,"user":{"displayName":"Beyza Ecem Erce","userId":"07724844839373940404"}}},"outputs":[],"source":["import random\n","import torch\n","import torchvision\n","from torch.utils.data import TensorDataset\n","from tqdm.auto import tqdm\n","import pandas as pd\n","import numpy as np\n","from torch.autograd import Variable\n","from sklearn.preprocessing import MinMaxScaler\n","import torch\n","import torch.nn as nn\n","from sklearn.preprocessing import StandardScaler\n","from math import sqrt\n","import math, time\n","from sklearn.metrics import mean_squared_error,mean_absolute_percentage_error\n","from torch.utils.data import DataLoader\n","\n","from itertools import cycle\n","import plotly.graph_objects as go\n","import plotly.express as px\n","from plotly.subplots import make_subplots"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":16100,"status":"ok","timestamp":1672765615813,"user":{"displayName":"Beyza Ecem Erce","userId":"07724844839373940404"},"user_tz":-180},"id":"57PynzXjjflC","outputId":"96015341-27e2-4fc5-c31e-a7c703cfa889"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/gdrive\n"]}],"source":["#this block was only used to connect the google drive for colab implementations\n","#if you're working on your local, please skip this part\n","\n","from google.colab import drive\n","drive.mount('/content/gdrive')"]},{"cell_type":"code","source":["#please add sys path to reach the modules of the functions\n","\n","import sys\n","sys.path.append('/content/gdrive/MyDrive/Colab Notebooks/DataCraft_notebook/Code files/One py for each application/')"],"metadata":{"id":"VG5z87WHyqaz","executionInfo":{"status":"ok","timestamp":1672765615813,"user_tz":-180,"elapsed":4,"user":{"displayName":"Beyza Ecem Erce","userId":"07724844839373940404"}}},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":["## FUNCTIONS"],"metadata":{"id":"R73SoNGECjCr"}},{"cell_type":"code","source":["#import cerated early stopping, LSTM model and sequence functions in py files\n","\n","from earlyStopping import EarlyStopping\n","from LSTM_model import LSTM\n","from sequenceDataset import SequenceDataset"],"metadata":{"id":"nx4PrGnfysN6","executionInfo":{"status":"ok","timestamp":1672765617847,"user_tz":-180,"elapsed":2036,"user":{"displayName":"Beyza Ecem Erce","userId":"07724844839373940404"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","execution_count":7,"metadata":{"id":"3ALtrrusrhHj","executionInfo":{"status":"ok","timestamp":1672765617848,"user_tz":-180,"elapsed":5,"user":{"displayName":"Beyza Ecem Erce","userId":"07724844839373940404"}}},"outputs":[],"source":["def split(df, SeqLen): #splitdataset\n","  split = [int(len(df)*0.8), int(len(df)*0.9)] #give split index for train, valid, test\n","  train = df[:split[0]]  #~%80\n","  val = df[split[0]-SeqLen:split[1]] # ~%10\n","  test = df[split[1]-SeqLen:]  # ~%10\n","  return train, val, test"]},{"cell_type":"code","source":["#create evaluation function to get the MAPE and MSE scores of the train, test, validation dataset\n","\n","def evaluation(split,scaled,Steps,model,loader,criterion,scaler):\n","  #calculate test loss, MSE and MAPE   \n","  loss=0    \n","  y_pred = torch.tensor([]).cuda()\n","  y=torch.tensor([]).cuda()\n","  y=torch.reshape(y, (-1,))\n","  y_pred=torch.reshape(y_pred, (-1,))\n","  model.eval()\n","  with torch.no_grad():\n","      for X, Y in loader:\n","          X=X.cuda()\n","          Y=Y.cuda()\n","          y = torch.cat((y, Y), 0)\n","          predict = model(X)\n","          \n","          predict=torch.reshape(predict, (-1,))\n","          y_pred = torch.cat((y_pred.cuda(), predict), 0)\n","          loss += criterion(y_pred, y).item()\n","\n","  avg_loss = loss / Steps\n","  print(\"{} loss:\".format(split),avg_loss)\n","\n","  #reshape, concatenate, and apply inverse scaler transform to calculate the error values\n","  scaled_open=np.reshape(scaled[:,1], (-1,1))\n","  y_pred=np.reshape(y_pred.cpu().detach().numpy(), (-1,1))\n","  pred_open=np.concatenate((y_pred, scaled_open), axis=1)\n","  pred_open = scaler.inverse_transform(pred_open)\n","  price_open=np.concatenate((np.reshape(y.cpu().detach().numpy(), (-1,1)), scaled_open), axis=1)\n","  price_open = scaler.inverse_transform(price_open)\n","\n","  mse_score = mean_squared_error(price_open[:,0], pred_open[:,0])\n","  print(split+' MSE: %.2f MSE' % (mse_score))\n","\n","  mape_score = mean_absolute_percentage_error(price_open[:,0], pred_open[:,0])\n","  print(split+\" MAPE:\",mape_score)\n","\n","  return (mape_score,mse_score)\n"],"metadata":{"id":"C3bXh3vJ2I3v","executionInfo":{"status":"ok","timestamp":1672765617848,"user_tz":-180,"elapsed":4,"user":{"displayName":"Beyza Ecem Erce","userId":"07724844839373940404"}}},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":["## DATASET"],"metadata":{"id":"dCJlIYxvWC-y"}},{"cell_type":"markdown","source":["The code user should indicate which dataset will be processed in this notebook. Because there are 3 different datasets belonging to the 3 different companies. These include the stock prices of Apple, Samsung, and Xiaomi companies.\n","\n","And also each company has its own target MAPE test scores to reach business objectives which are given in the Project Charter Document. So, MAPE test goals are indicated to save the model that has reached this target value.\n","\n","Don't forget business objectives MAPE test values should be at least %10 less than the baseline MAPE test results. So, the \"mape_test_score_goal\" values were detected according to the baseline results."],"metadata":{"id":"FphucXl4V8K0"}},{"cell_type":"code","source":["#initialize the variables\n","company = \"Apple\"\n","mape_test_score_goal = 0 #keep business objective"],"metadata":{"id":"GdRMhp7gWsoY","executionInfo":{"status":"ok","timestamp":1672765617848,"user_tz":-180,"elapsed":4,"user":{"displayName":"Beyza Ecem Erce","userId":"07724844839373940404"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["#get the datset\n","with wandb.init(project=\"DSS\") as r:\n","         \n","        # ✔️ declare which artifact we'll be using\n","        if company == 'Apple':\n","          artifact = r.use_artifact('metu_datacraft/DSS/Apple:v2', type='Data')\n","          mape_test_score_goal = 0.014968 \n","        elif company == 'Samsung':\n","          artifact = r.use_artifact('metu_datacraft/DSS/Samsung:v2', type='Data')\n","          mape_test_score_goal = 0.0099\n","        elif company == 'Xiaomi':\n","          artifact = r.use_artifact('metu_datacraft/DSS/Xiaomi:v2', type='Data')\n","          mape_test_score_goal = 0.0205\n","        else:\n","          raise Exception(\"Sorry, please enter the company name correctly\")\n","\n","        table = artifact.get('weekday_data')\n","        dataset= {\"Date\": table.get_column(\"Date\"),\"Price\":table.get_column(\"Price\"),\"Open\":table.get_column(\"Open\"),\n","                  \"High\":table.get_column(\"High\"), \"Low\":table.get_column(\"Low\") , \"Volume\": table.get_column(\"Volume\"),\n","                  \"Change\":table.get_column(\"Change\")}\n","        data = pd.DataFrame(dataset)"],"metadata":{"id":"c7RiNccdWwcJ","colab":{"base_uri":"https://localhost:8080/","height":237,"referenced_widgets":["86a96b225d1049458950f40b09179954","e8f923af5fec463c8d146659e9405b09","82e0951974fa4b41889bd9e6ceafb5f4","d6d710abdb05471b8f567ec3fed6af61","3f2ba4404eb8459a90839482b918ace7","aba446c5a4ab4203ac06d51bf109c483","92126f75e1934a0faf46d54fdd0a95b7","055348133f854e0d8b1ab4d59cbbf608"]},"executionInfo":{"status":"ok","timestamp":1672765628437,"user_tz":-180,"elapsed":7260,"user":{"displayName":"Beyza Ecem Erce","userId":"07724844839373940404"}},"outputId":"b11be277-67d2-4397-c3c1-81311f9e1f37"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mbecemerce\u001b[0m (\u001b[33mmetu_datacraft\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Tracking run with wandb version 0.13.7"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Run data is saved locally in <code>/content/wandb/run-20230103_170701-1am4j37s</code>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Syncing run <strong><a href=\"https://wandb.ai/metu_datacraft/DSS/runs/1am4j37s\" target=\"_blank\">stellar-moon-3450</a></strong> to <a href=\"https://wandb.ai/metu_datacraft/DSS\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mwandb\u001b[0m:   1 of 1 files downloaded.  \n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"86a96b225d1049458950f40b09179954"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Synced <strong style=\"color:#cdcd00\">stellar-moon-3450</strong>: <a href=\"https://wandb.ai/metu_datacraft/DSS/runs/1am4j37s\" target=\"_blank\">https://wandb.ai/metu_datacraft/DSS/runs/1am4j37s</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Find logs at: <code>./wandb/run-20230103_170701-1am4j37s/logs</code>"]},"metadata":{}}]},{"cell_type":"markdown","source":["For only Apple dataset, the dataset had to be filtered to get high performance on the model prediction. This filtering issue was not applied on the other datasets belong to Samsung and Xiaomi. "],"metadata":{"id":"Am8MPC4NX-2W"}},{"cell_type":"code","source":["#the data was filtered to get the values of stock prices after the year 2020 to get more powerful model\n","#this block is valid only for Apple dataset\n","if company == 'Apple':\n","  data['Date'] = pd.to_datetime(data.Date)\n","  data = data[data['Date']>'2020-01-01']\n","  data.reset_index(inplace=True)\n","  data.drop(columns={'index'},inplace=True)"],"metadata":{"id":"DQrPCxo5X6VR","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1672765628438,"user_tz":-180,"elapsed":6,"user":{"displayName":"Beyza Ecem Erce","userId":"07724844839373940404"}},"outputId":"4ee37489-f4fd-4033-9bf8-3cbaf5c4cc7f"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.8/dist-packages/pandas/core/frame.py:4906: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  return super().drop(\n"]}]},{"cell_type":"code","source":["data"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":424},"id":"lxBCg9YxmdjL","executionInfo":{"status":"ok","timestamp":1672765643416,"user_tz":-180,"elapsed":377,"user":{"displayName":"Beyza Ecem Erce","userId":"07724844839373940404"}},"outputId":"ec92207b-2faf-47ca-ef67-7b87f1aaca46"},"execution_count":12,"outputs":[{"output_type":"execute_result","data":{"text/plain":["          Date   Price    Open    High     Low  Volume  Change\n","0   2020-01-02   75.09   74.06   75.15   73.80  135.65    2.29\n","1   2020-01-03   74.36   74.29   75.14   74.12  146.54   -0.97\n","2   2020-01-06   74.95   73.45   74.99   73.19  118.58    0.79\n","3   2020-01-07   74.60   74.96   75.22   74.37  111.51   -0.47\n","4   2020-01-08   75.80   74.29   76.11   74.29  132.36    1.61\n","..         ...     ...     ...     ...     ...     ...     ...\n","733 2022-10-25  152.34  150.09  152.49  149.36   74.73    1.93\n","734 2022-10-26  149.35  150.96  151.99  148.04   87.74   -1.96\n","735 2022-10-27  144.80  148.07  149.05  144.13   95.29   -3.05\n","736 2022-10-28  155.74  148.20  157.50  147.82  163.87    7.56\n","737 2022-10-31  153.34  153.20  154.24  151.97   97.77   -1.54\n","\n","[738 rows x 7 columns]"],"text/html":["\n","  <div id=\"df-ee4bd2d5-79cc-484f-890b-75a47f41109e\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Date</th>\n","      <th>Price</th>\n","      <th>Open</th>\n","      <th>High</th>\n","      <th>Low</th>\n","      <th>Volume</th>\n","      <th>Change</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>2020-01-02</td>\n","      <td>75.09</td>\n","      <td>74.06</td>\n","      <td>75.15</td>\n","      <td>73.80</td>\n","      <td>135.65</td>\n","      <td>2.29</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2020-01-03</td>\n","      <td>74.36</td>\n","      <td>74.29</td>\n","      <td>75.14</td>\n","      <td>74.12</td>\n","      <td>146.54</td>\n","      <td>-0.97</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2020-01-06</td>\n","      <td>74.95</td>\n","      <td>73.45</td>\n","      <td>74.99</td>\n","      <td>73.19</td>\n","      <td>118.58</td>\n","      <td>0.79</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>2020-01-07</td>\n","      <td>74.60</td>\n","      <td>74.96</td>\n","      <td>75.22</td>\n","      <td>74.37</td>\n","      <td>111.51</td>\n","      <td>-0.47</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>2020-01-08</td>\n","      <td>75.80</td>\n","      <td>74.29</td>\n","      <td>76.11</td>\n","      <td>74.29</td>\n","      <td>132.36</td>\n","      <td>1.61</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>733</th>\n","      <td>2022-10-25</td>\n","      <td>152.34</td>\n","      <td>150.09</td>\n","      <td>152.49</td>\n","      <td>149.36</td>\n","      <td>74.73</td>\n","      <td>1.93</td>\n","    </tr>\n","    <tr>\n","      <th>734</th>\n","      <td>2022-10-26</td>\n","      <td>149.35</td>\n","      <td>150.96</td>\n","      <td>151.99</td>\n","      <td>148.04</td>\n","      <td>87.74</td>\n","      <td>-1.96</td>\n","    </tr>\n","    <tr>\n","      <th>735</th>\n","      <td>2022-10-27</td>\n","      <td>144.80</td>\n","      <td>148.07</td>\n","      <td>149.05</td>\n","      <td>144.13</td>\n","      <td>95.29</td>\n","      <td>-3.05</td>\n","    </tr>\n","    <tr>\n","      <th>736</th>\n","      <td>2022-10-28</td>\n","      <td>155.74</td>\n","      <td>148.20</td>\n","      <td>157.50</td>\n","      <td>147.82</td>\n","      <td>163.87</td>\n","      <td>7.56</td>\n","    </tr>\n","    <tr>\n","      <th>737</th>\n","      <td>2022-10-31</td>\n","      <td>153.34</td>\n","      <td>153.20</td>\n","      <td>154.24</td>\n","      <td>151.97</td>\n","      <td>97.77</td>\n","      <td>-1.54</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>738 rows × 7 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ee4bd2d5-79cc-484f-890b-75a47f41109e')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-ee4bd2d5-79cc-484f-890b-75a47f41109e button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-ee4bd2d5-79cc-484f-890b-75a47f41109e');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":12}]},{"cell_type":"markdown","metadata":{"id":"LXAJSmiTreq4"},"source":["## FINE TUNING"]},{"cell_type":"markdown","source":["In this section, after the architecture tuning, the following steps were applied to the LSTM model for the hyperparameter tuning and model performance improvement;\n","* Xavier initiation\n","* Learning rate scheduler \n","* Batch size tuning\n","* Sequence size tuning\n"],"metadata":{"id":"wGkyGQt7Rqd3"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"IjCYiOh4rhHi"},"outputs":[],"source":["DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uGo0swv0r8BK"},"outputs":[],"source":["#create sweep config for the fine tuning\n","\n","sweep_config = {  #This sweep was created for a generalized purpose, and it will take a long time to conclude. When creating sweeps, parameters can be given discrete values to reduce run time.\n","    #for more information https://docs.wandb.ai/guides/sweeps/define-sweep-configuration\n","    'method': 'bayes', #grid, random, bayes\n","     'metric': {\n","      'name': 'average_train_loss',\n","      'goal': 'minimize'   \n","    },\n","    'metric': {\n","      'name': 'average_valid_loss',\n","      'goal': 'minimize'   \n","    },\n","    'parameters': {\n","        'seq_len': { # Small sequence lengths shift input to obtain the output. \n","            'distribution': 'int_uniform',\n","            'min': 1,\n","            'max': 90\n","        },\n","        'batch_size': {\n","           'distribution': 'int_uniform',\n","             'min': 4,\n","             'max': 128\n","        },\n","        'hidden_size': {\n","            'values': [8]\n","        },\n","        'num_layers' :{\n","            'values': [1]\n","        },\n","        }\n","    }\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":454,"status":"ok","timestamp":1672519450422,"user":{"displayName":"Beyza Ecem Erce","userId":"07724844839373940404"},"user_tz":-180},"id":"oxNO_a_arhHi","outputId":"38b1c643-1f50-4f16-8876-6ab20a4598a7"},"outputs":[{"output_type":"stream","name":"stdout","text":["Create sweep with ID: owq2i7p2\n","Sweep URL: https://wandb.ai/metu_datacraft/DSS/sweeps/owq2i7p2\n"]}],"source":["#create sweep id\n","sweep_id = wandb.sweep(sweep_config, project=\"DSS\", entity=\"metu_datacraft\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bX-Z7mQxrhHi"},"outputs":[],"source":["#give constant parameters for the fine tuning\n","#input and output dimension should be 'one'\n","input_dim = 1\n","output_dim = 1\n","n_epochs=500000"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":66990,"status":"ok","timestamp":1672521252970,"user":{"displayName":"Beyza Ecem Erce","userId":"07724844839373940404"},"user_tz":-180},"id":"P1735CwNrhHj","outputId":"1a9cd272-c3b7-4c40-e6c7-f11a263bb756"},"outputs":[{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 2pizc3ny with config:\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 19\n","\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_size: 8\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_layers: 1\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tseq_len: 55\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Tracking run with wandb version 0.13.7"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Run data is saved locally in <code>/content/wandb/run-20221231_211308-2pizc3ny</code>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Syncing run <strong><a href=\"https://wandb.ai/metu_datacraft/DSS/runs/2pizc3ny\" target=\"_blank\">autumn-sweep-25</a></strong> to <a href=\"https://wandb.ai/metu_datacraft/DSS\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/metu_datacraft/DSS/sweeps/owq2i7p2\" target=\"_blank\">https://wandb.ai/metu_datacraft/DSS/sweeps/owq2i7p2</a>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Epoch: 0, Train loss: 1.03740, Valid loss: 1.5311639\n","Epoch: 1, Train loss: 0.87680, Valid loss: 1.1697037\n","Epoch: 2, Train loss: 0.69022, Valid loss: 0.7424261\n","Epoch: 3, Train loss: 0.37455, Valid loss: 0.3867288\n","Epoch: 4, Train loss: 0.20647, Valid loss: 0.2245779\n","Epoch: 5, Train loss: 0.13772, Valid loss: 0.1669071\n","Epoch: 6, Train loss: 0.09999, Valid loss: 0.1165178\n","Epoch: 7, Train loss: 0.07200, Valid loss: 0.0830216\n","Epoch: 8, Train loss: 0.04971, Valid loss: 0.0601044\n","Epoch: 9, Train loss: 0.03652, Valid loss: 0.0478657\n","Epoch: 10, Train loss: 0.03459, Valid loss: 0.0417735\n","Epoch: 11, Train loss: 0.02277, Valid loss: 0.0410911\n","Epoch: 12, Train loss: 0.01942, Valid loss: 0.0425829\n","EarlyStopping counter: 1 out of 20\n","Epoch: 13, Train loss: 0.01791, Valid loss: 0.0408229\n","Epoch: 14, Train loss: 0.01662, Valid loss: 0.0417162\n","EarlyStopping counter: 1 out of 20\n","Epoch: 15, Train loss: 0.01599, Valid loss: 0.0409769\n","EarlyStopping counter: 2 out of 20\n","Epoch: 16, Train loss: 0.01691, Valid loss: 0.0416407\n","EarlyStopping counter: 3 out of 20\n","Epoch: 17, Train loss: 0.01558, Valid loss: 0.0383548\n","Epoch: 18, Train loss: 0.01497, Valid loss: 0.0374625\n","Epoch: 19, Train loss: 0.01364, Valid loss: 0.0325690\n","Epoch: 20, Train loss: 0.01284, Valid loss: 0.0342796\n","EarlyStopping counter: 1 out of 20\n","Epoch: 21, Train loss: 0.01235, Valid loss: 0.0316870\n","Epoch: 22, Train loss: 0.01256, Valid loss: 0.0336282\n","EarlyStopping counter: 1 out of 20\n","Epoch: 23, Train loss: 0.01175, Valid loss: 0.0305255\n","Epoch: 24, Train loss: 0.01131, Valid loss: 0.0294545\n","Epoch: 25, Train loss: 0.01105, Valid loss: 0.0278293\n","Epoch: 26, Train loss: 0.01086, Valid loss: 0.0268916\n","Epoch: 27, Train loss: 0.01112, Valid loss: 0.0270421\n","EarlyStopping counter: 1 out of 20\n","Epoch: 28, Train loss: 0.01098, Valid loss: 0.0281911\n","EarlyStopping counter: 2 out of 20\n","Epoch: 29, Train loss: 0.01051, Valid loss: 0.0275165\n","EarlyStopping counter: 3 out of 20\n","Epoch: 30, Train loss: 0.01224, Valid loss: 0.0250302\n","Epoch: 31, Train loss: 0.01052, Valid loss: 0.0235991\n","Epoch: 32, Train loss: 0.00935, Valid loss: 0.0255810\n","EarlyStopping counter: 1 out of 20\n","Epoch: 33, Train loss: 0.00919, Valid loss: 0.0226615\n","Epoch: 34, Train loss: 0.00898, Valid loss: 0.0228207\n","EarlyStopping counter: 1 out of 20\n","Epoch: 35, Train loss: 0.00876, Valid loss: 0.0229373\n","EarlyStopping counter: 2 out of 20\n","Epoch: 36, Train loss: 0.00869, Valid loss: 0.0214261\n","Epoch: 37, Train loss: 0.00849, Valid loss: 0.0216701\n","EarlyStopping counter: 1 out of 20\n","Epoch: 38, Train loss: 0.00862, Valid loss: 0.0202748\n","Epoch: 39, Train loss: 0.00840, Valid loss: 0.0218492\n","EarlyStopping counter: 1 out of 20\n","Epoch: 40, Train loss: 0.00830, Valid loss: 0.0202820\n","EarlyStopping counter: 2 out of 20\n","Epoch: 41, Train loss: 0.00803, Valid loss: 0.0198354\n","Epoch: 42, Train loss: 0.00799, Valid loss: 0.0195214\n","Epoch: 43, Train loss: 0.00836, Valid loss: 0.0206811\n","EarlyStopping counter: 1 out of 20\n","Epoch: 44, Train loss: 0.00809, Valid loss: 0.0187612\n","Epoch: 45, Train loss: 0.00753, Valid loss: 0.0180694\n","Epoch: 46, Train loss: 0.00738, Valid loss: 0.0189542\n","EarlyStopping counter: 1 out of 20\n","Epoch: 47, Train loss: 0.00734, Valid loss: 0.0176962\n","Epoch: 48, Train loss: 0.00727, Valid loss: 0.0179397\n","EarlyStopping counter: 1 out of 20\n","Epoch: 49, Train loss: 0.00711, Valid loss: 0.0185139\n","EarlyStopping counter: 2 out of 20\n","Epoch: 50, Train loss: 0.00723, Valid loss: 0.0168577\n","Epoch: 51, Train loss: 0.00699, Valid loss: 0.0167124\n","Epoch: 52, Train loss: 0.00687, Valid loss: 0.0167994\n","EarlyStopping counter: 1 out of 20\n","Epoch: 53, Train loss: 0.00681, Valid loss: 0.0171983\n","EarlyStopping counter: 2 out of 20\n","Epoch: 54, Train loss: 0.00709, Valid loss: 0.0178804\n","EarlyStopping counter: 3 out of 20\n","Epoch: 55, Train loss: 0.00755, Valid loss: 0.0161809\n","Epoch: 56, Train loss: 0.00668, Valid loss: 0.0155771\n","Epoch: 57, Train loss: 0.00788, Valid loss: 0.0163921\n","EarlyStopping counter: 1 out of 20\n","Epoch: 58, Train loss: 0.00700, Valid loss: 0.0172244\n","EarlyStopping counter: 2 out of 20\n","Epoch: 59, Train loss: 0.00656, Valid loss: 0.0157265\n","EarlyStopping counter: 3 out of 20\n","Epoch: 60, Train loss: 0.00638, Valid loss: 0.0151706\n","Epoch: 61, Train loss: 0.00729, Valid loss: 0.0155880\n","EarlyStopping counter: 1 out of 20\n","Epoch: 62, Train loss: 0.00654, Valid loss: 0.0149840\n","Epoch: 63, Train loss: 0.00624, Valid loss: 0.0154839\n","EarlyStopping counter: 1 out of 20\n","Epoch: 64, Train loss: 0.00663, Valid loss: 0.0144893\n","Epoch: 65, Train loss: 0.00629, Valid loss: 0.0139836\n","Epoch: 66, Train loss: 0.00603, Valid loss: 0.0143105\n","EarlyStopping counter: 1 out of 20\n","Epoch: 67, Train loss: 0.00596, Valid loss: 0.0140719\n","EarlyStopping counter: 2 out of 20\n","Epoch: 68, Train loss: 0.00657, Valid loss: 0.0140396\n","EarlyStopping counter: 3 out of 20\n","Epoch: 69, Train loss: 0.00631, Valid loss: 0.0142681\n","EarlyStopping counter: 4 out of 20\n","Epoch: 70, Train loss: 0.00690, Valid loss: 0.0134905\n","Epoch: 71, Train loss: 0.00596, Valid loss: 0.0133729\n","Epoch: 72, Train loss: 0.00569, Valid loss: 0.0131872\n","Epoch: 73, Train loss: 0.00573, Valid loss: 0.0131769\n","EarlyStopping counter: 1 out of 20\n","Epoch: 74, Train loss: 0.00563, Valid loss: 0.0133202\n","EarlyStopping counter: 2 out of 20\n","Epoch: 75, Train loss: 0.00563, Valid loss: 0.0132458\n","EarlyStopping counter: 3 out of 20\n","Epoch: 76, Train loss: 0.00551, Valid loss: 0.0129704\n","Epoch: 77, Train loss: 0.00552, Valid loss: 0.0128546\n","Epoch: 78, Train loss: 0.00552, Valid loss: 0.0131985\n","EarlyStopping counter: 1 out of 20\n","Epoch: 79, Train loss: 0.00588, Valid loss: 0.0128284\n","EarlyStopping counter: 2 out of 20\n","Epoch: 80, Train loss: 0.00563, Valid loss: 0.0127711\n","EarlyStopping counter: 3 out of 20\n","Epoch: 81, Train loss: 0.00539, Valid loss: 0.0125815\n","Epoch: 82, Train loss: 0.00550, Valid loss: 0.0127087\n","EarlyStopping counter: 1 out of 20\n","Epoch: 83, Train loss: 0.00550, Valid loss: 0.0126341\n","EarlyStopping counter: 2 out of 20\n","Epoch: 84, Train loss: 0.00613, Valid loss: 0.0125314\n","EarlyStopping counter: 3 out of 20\n","Epoch: 85, Train loss: 0.00540, Valid loss: 0.0127217\n","EarlyStopping counter: 4 out of 20\n","Epoch: 86, Train loss: 0.00540, Valid loss: 0.0123731\n","Epoch: 87, Train loss: 0.00588, Valid loss: 0.0127690\n","EarlyStopping counter: 1 out of 20\n","Epoch: 88, Train loss: 0.00543, Valid loss: 0.0120870\n","Epoch: 89, Train loss: 0.00563, Valid loss: 0.0121775\n","EarlyStopping counter: 1 out of 20\n","Epoch: 90, Train loss: 0.00513, Valid loss: 0.0125812\n","EarlyStopping counter: 2 out of 20\n","Epoch: 91, Train loss: 0.00530, Valid loss: 0.0124122\n","EarlyStopping counter: 3 out of 20\n","Epoch: 92, Train loss: 0.00522, Valid loss: 0.0120512\n","EarlyStopping counter: 4 out of 20\n","Epoch: 93, Train loss: 0.00503, Valid loss: 0.0120544\n","EarlyStopping counter: 5 out of 20\n","Epoch: 94, Train loss: 0.00504, Valid loss: 0.0121102\n","EarlyStopping counter: 6 out of 20\n","Epoch: 95, Train loss: 0.00498, Valid loss: 0.0118244\n","Epoch: 96, Train loss: 0.00509, Valid loss: 0.0117229\n","Epoch: 97, Train loss: 0.00493, Valid loss: 0.0118088\n","EarlyStopping counter: 1 out of 20\n","Epoch: 98, Train loss: 0.00484, Valid loss: 0.0117256\n","EarlyStopping counter: 2 out of 20\n","Epoch: 99, Train loss: 0.00490, Valid loss: 0.0116580\n","EarlyStopping counter: 3 out of 20\n","Epoch: 100, Train loss: 0.00487, Valid loss: 0.0117383\n","EarlyStopping counter: 4 out of 20\n","Epoch: 101, Train loss: 0.00477, Valid loss: 0.0116614\n","EarlyStopping counter: 5 out of 20\n","Epoch: 102, Train loss: 0.00477, Valid loss: 0.0115012\n","Epoch: 103, Train loss: 0.00477, Valid loss: 0.0115233\n","EarlyStopping counter: 1 out of 20\n","Epoch: 104, Train loss: 0.00476, Valid loss: 0.0114234\n","EarlyStopping counter: 2 out of 20\n","Epoch: 105, Train loss: 0.00514, Valid loss: 0.0124614\n","EarlyStopping counter: 3 out of 20\n","Epoch: 106, Train loss: 0.00510, Valid loss: 0.0117040\n","EarlyStopping counter: 4 out of 20\n","Epoch: 107, Train loss: 0.00475, Valid loss: 0.0114113\n","EarlyStopping counter: 5 out of 20\n","Epoch: 108, Train loss: 0.00480, Valid loss: 0.0112976\n","Epoch: 109, Train loss: 0.00482, Valid loss: 0.0115851\n","EarlyStopping counter: 1 out of 20\n","Epoch: 110, Train loss: 0.00476, Valid loss: 0.0113771\n","EarlyStopping counter: 2 out of 20\n","Epoch: 111, Train loss: 0.00469, Valid loss: 0.0110913\n","Epoch: 112, Train loss: 0.00482, Valid loss: 0.0118644\n","EarlyStopping counter: 1 out of 20\n","Epoch: 113, Train loss: 0.00470, Valid loss: 0.0113601\n","EarlyStopping counter: 2 out of 20\n","Epoch: 114, Train loss: 0.00458, Valid loss: 0.0114844\n","EarlyStopping counter: 3 out of 20\n","Epoch: 115, Train loss: 0.00482, Valid loss: 0.0114794\n","EarlyStopping counter: 4 out of 20\n","Epoch: 116, Train loss: 0.00476, Valid loss: 0.0111331\n","EarlyStopping counter: 5 out of 20\n","Epoch: 117, Train loss: 0.00526, Valid loss: 0.0111340\n","EarlyStopping counter: 6 out of 20\n","Epoch: 118, Train loss: 0.00510, Valid loss: 0.0111296\n","EarlyStopping counter: 7 out of 20\n","Epoch: 119, Train loss: 0.00478, Valid loss: 0.0110567\n","EarlyStopping counter: 8 out of 20\n","Epoch: 120, Train loss: 0.00463, Valid loss: 0.0112823\n","EarlyStopping counter: 9 out of 20\n","Epoch: 121, Train loss: 0.00463, Valid loss: 0.0113154\n","EarlyStopping counter: 10 out of 20\n","Epoch: 122, Train loss: 0.00456, Valid loss: 0.0109717\n","Epoch: 123, Train loss: 0.00593, Valid loss: 0.0110679\n","EarlyStopping counter: 1 out of 20\n","Epoch: 124, Train loss: 0.00511, Valid loss: 0.0109119\n","EarlyStopping counter: 2 out of 20\n","Epoch: 125, Train loss: 0.00452, Valid loss: 0.0109510\n","EarlyStopping counter: 3 out of 20\n","Epoch: 126, Train loss: 0.00477, Valid loss: 0.0108073\n","Epoch: 127, Train loss: 0.00457, Valid loss: 0.0107311\n","EarlyStopping counter: 1 out of 20\n","Epoch: 128, Train loss: 0.00448, Valid loss: 0.0110803\n","EarlyStopping counter: 2 out of 20\n","Epoch: 129, Train loss: 0.00463, Valid loss: 0.0110849\n","EarlyStopping counter: 3 out of 20\n","Epoch: 130, Train loss: 0.00467, Valid loss: 0.0107454\n","EarlyStopping counter: 4 out of 20\n","Epoch: 131, Train loss: 0.00450, Valid loss: 0.0112166\n","EarlyStopping counter: 5 out of 20\n","Epoch: 132, Train loss: 0.00439, Valid loss: 0.0108482\n","EarlyStopping counter: 6 out of 20\n","Epoch: 133, Train loss: 0.00444, Valid loss: 0.0107284\n","EarlyStopping counter: 7 out of 20\n","Epoch: 134, Train loss: 0.00505, Valid loss: 0.0107110\n","EarlyStopping counter: 8 out of 20\n","Epoch: 135, Train loss: 0.00437, Valid loss: 0.0104980\n","Epoch: 136, Train loss: 0.00436, Valid loss: 0.0104585\n","EarlyStopping counter: 1 out of 20\n","Epoch: 137, Train loss: 0.00455, Valid loss: 0.0106679\n","EarlyStopping counter: 2 out of 20\n","Epoch: 138, Train loss: 0.00461, Valid loss: 0.0104383\n","EarlyStopping counter: 3 out of 20\n","Epoch: 139, Train loss: 0.00441, Valid loss: 0.0107898\n","EarlyStopping counter: 4 out of 20\n","Epoch: 140, Train loss: 0.00429, Valid loss: 0.0105123\n","EarlyStopping counter: 5 out of 20\n","Epoch: 141, Train loss: 0.00439, Valid loss: 0.0105216\n","EarlyStopping counter: 6 out of 20\n","Epoch: 142, Train loss: 0.00426, Valid loss: 0.0107477\n","EarlyStopping counter: 7 out of 20\n","Epoch: 143, Train loss: 0.00428, Valid loss: 0.0108383\n","EarlyStopping counter: 8 out of 20\n","Epoch: 144, Train loss: 0.00426, Valid loss: 0.0105117\n","EarlyStopping counter: 9 out of 20\n","Epoch: 145, Train loss: 0.00423, Valid loss: 0.0112398\n","EarlyStopping counter: 10 out of 20\n","Epoch: 146, Train loss: 0.00468, Valid loss: 0.0104241\n","EarlyStopping counter: 11 out of 20\n","Epoch: 147, Train loss: 0.00432, Valid loss: 0.0104674\n","EarlyStopping counter: 12 out of 20\n","Epoch: 148, Train loss: 0.00418, Valid loss: 0.0104924\n","EarlyStopping counter: 13 out of 20\n","Epoch: 149, Train loss: 0.00414, Valid loss: 0.0104439\n","EarlyStopping counter: 14 out of 20\n","Epoch: 150, Train loss: 0.00425, Valid loss: 0.0104466\n","EarlyStopping counter: 15 out of 20\n","Epoch: 151, Train loss: 0.00442, Valid loss: 0.0104366\n","EarlyStopping counter: 16 out of 20\n","Epoch: 152, Train loss: 0.00423, Valid loss: 0.0104029\n","EarlyStopping counter: 17 out of 20\n","Epoch: 153, Train loss: 0.00417, Valid loss: 0.0104087\n","EarlyStopping counter: 18 out of 20\n","Epoch: 154, Train loss: 0.00421, Valid loss: 0.0104428\n","EarlyStopping counter: 19 out of 20\n","Epoch: 155, Train loss: 0.00415, Valid loss: 0.0104363\n","EarlyStopping counter: 20 out of 20\n","Early stopping at epoch:  155\n","Test loss: 0.01190152857452631\n","Test MSE: 8.95 MSE\n","Test MAPE: 0.015572061773494891\n","Train loss: 0.011901531368494034\n","Train MSE: 8.95 MSE\n","Train MAPE: 0.015572064810444404\n","Valid loss: 0.011901527332762877\n","Valid MSE: 8.95 MSE\n","Valid MAPE: 0.015572063908802888\n","HERE\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["<style>\n","    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n","    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n","    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n","    </style>\n","<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>average_train_loss</td><td>█▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>average_valid_loss</td><td>█▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>mape_test_score</td><td>▁</td></tr><tr><td>mape_train_score</td><td>▁</td></tr><tr><td>mse_test_score</td><td>▁</td></tr><tr><td>mse_train_score</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Epoch</td><td>155</td></tr><tr><td>average_train_loss</td><td>0.00415</td></tr><tr><td>average_valid_loss</td><td>0.01044</td></tr><tr><td>mape_test_score</td><td>0.01557</td></tr><tr><td>mape_train_score</td><td>0.01557</td></tr><tr><td>mse_test_score</td><td>8.95144</td></tr><tr><td>mse_train_score</td><td>8.95144</td></tr></table><br/></div></div>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Synced <strong style=\"color:#cdcd00\">autumn-sweep-25</strong>: <a href=\"https://wandb.ai/metu_datacraft/DSS/runs/2pizc3ny\" target=\"_blank\">https://wandb.ai/metu_datacraft/DSS/runs/2pizc3ny</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Find logs at: <code>./wandb/run-20221231_211308-2pizc3ny/logs</code>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: r3dmh2my with config:\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 113\n","\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_size: 8\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_layers: 1\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tseq_len: 15\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Tracking run with wandb version 0.13.7"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Run data is saved locally in <code>/content/wandb/run-20221231_211338-r3dmh2my</code>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Syncing run <strong><a href=\"https://wandb.ai/metu_datacraft/DSS/runs/r3dmh2my\" target=\"_blank\">twilight-sweep-26</a></strong> to <a href=\"https://wandb.ai/metu_datacraft/DSS\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/metu_datacraft/DSS/sweeps/owq2i7p2\" target=\"_blank\">https://wandb.ai/metu_datacraft/DSS/sweeps/owq2i7p2</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Waiting for W&B process to finish... <strong style=\"color:red\">(failed 1).</strong> Press Control-C to abort syncing."]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Synced <strong style=\"color:#cdcd00\">twilight-sweep-26</strong>: <a href=\"https://wandb.ai/metu_datacraft/DSS/runs/r3dmh2my\" target=\"_blank\">https://wandb.ai/metu_datacraft/DSS/runs/r3dmh2my</a><br/>Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Find logs at: <code>./wandb/run-20221231_211338-r3dmh2my/logs</code>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Run r3dmh2my errored: ZeroDivisionError('float division by zero')\n","\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: aprik6hl with config:\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 60\n","\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_size: 8\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_layers: 1\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tseq_len: 26\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Tracking run with wandb version 0.13.7"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Run data is saved locally in <code>/content/wandb/run-20221231_211349-aprik6hl</code>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Syncing run <strong><a href=\"https://wandb.ai/metu_datacraft/DSS/runs/aprik6hl\" target=\"_blank\">mild-sweep-27</a></strong> to <a href=\"https://wandb.ai/metu_datacraft/DSS\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/metu_datacraft/DSS/sweeps/owq2i7p2\" target=\"_blank\">https://wandb.ai/metu_datacraft/DSS/sweeps/owq2i7p2</a>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Epoch: 0, Train loss: 1.30563, Valid loss: 0.8923838\n","Epoch: 1, Train loss: 1.25210, Valid loss: 0.9002700\n","EarlyStopping counter: 1 out of 20\n","Epoch: 2, Train loss: 1.20955, Valid loss: 0.9043733\n","EarlyStopping counter: 2 out of 20\n","Epoch: 3, Train loss: 1.15560, Valid loss: 0.9090718\n","EarlyStopping counter: 3 out of 20\n","Epoch: 4, Train loss: 1.10008, Valid loss: 0.9029711\n","EarlyStopping counter: 4 out of 20\n","Epoch: 5, Train loss: 1.03519, Valid loss: 0.8963703\n","EarlyStopping counter: 5 out of 20\n","Epoch: 6, Train loss: 0.97080, Valid loss: 0.8795859\n","Epoch: 7, Train loss: 0.89625, Valid loss: 0.8583258\n","Epoch: 8, Train loss: 0.81463, Valid loss: 0.8231944\n","Epoch: 9, Train loss: 0.72819, Valid loss: 0.7720358\n","Epoch: 10, Train loss: 0.64133, Valid loss: 0.7033899\n","Epoch: 11, Train loss: 0.56245, Valid loss: 0.6312790\n","Epoch: 12, Train loss: 0.48912, Valid loss: 0.5561036\n","Epoch: 13, Train loss: 0.42281, Valid loss: 0.4882446\n","Epoch: 14, Train loss: 0.36459, Valid loss: 0.4244357\n","Epoch: 15, Train loss: 0.31994, Valid loss: 0.3727492\n","Epoch: 16, Train loss: 0.27912, Valid loss: 0.3252748\n","Epoch: 17, Train loss: 0.23733, Valid loss: 0.2822777\n","Epoch: 18, Train loss: 0.19987, Valid loss: 0.2421185\n","Epoch: 19, Train loss: 0.16707, Valid loss: 0.2072813\n","Epoch: 20, Train loss: 0.13767, Valid loss: 0.1852815\n","Epoch: 21, Train loss: 0.11580, Valid loss: 0.1678880\n","Epoch: 22, Train loss: 0.09779, Valid loss: 0.1534657\n","Epoch: 23, Train loss: 0.08451, Valid loss: 0.1348425\n","Epoch: 24, Train loss: 0.07179, Valid loss: 0.1141613\n","Epoch: 25, Train loss: 0.06211, Valid loss: 0.1011974\n","Epoch: 26, Train loss: 0.05312, Valid loss: 0.0956094\n","Epoch: 27, Train loss: 0.04636, Valid loss: 0.0919818\n","Epoch: 28, Train loss: 0.04081, Valid loss: 0.0949590\n","EarlyStopping counter: 1 out of 20\n","Epoch: 29, Train loss: 0.03692, Valid loss: 0.0968191\n","EarlyStopping counter: 2 out of 20\n","Epoch: 30, Train loss: 0.03381, Valid loss: 0.1009053\n","EarlyStopping counter: 3 out of 20\n","Epoch: 31, Train loss: 0.03117, Valid loss: 0.1064732\n","EarlyStopping counter: 4 out of 20\n","Epoch: 32, Train loss: 0.02927, Valid loss: 0.1106228\n","EarlyStopping counter: 5 out of 20\n","Epoch: 33, Train loss: 0.02770, Valid loss: 0.1107373\n","EarlyStopping counter: 6 out of 20\n","Epoch: 34, Train loss: 0.02619, Valid loss: 0.1140839\n","EarlyStopping counter: 7 out of 20\n","Epoch: 35, Train loss: 0.02517, Valid loss: 0.1191414\n","EarlyStopping counter: 8 out of 20\n","Epoch: 36, Train loss: 0.02445, Valid loss: 0.1173397\n","EarlyStopping counter: 9 out of 20\n","Epoch: 37, Train loss: 0.02328, Valid loss: 0.1171307\n","EarlyStopping counter: 10 out of 20\n","Epoch: 38, Train loss: 0.02262, Valid loss: 0.1165342\n","EarlyStopping counter: 11 out of 20\n","Epoch: 39, Train loss: 0.02212, Valid loss: 0.1168434\n","EarlyStopping counter: 12 out of 20\n","Epoch: 40, Train loss: 0.02210, Valid loss: 0.1162994\n","EarlyStopping counter: 13 out of 20\n","Epoch: 41, Train loss: 0.02198, Valid loss: 0.1162769\n","EarlyStopping counter: 14 out of 20\n","Epoch: 42, Train loss: 0.02190, Valid loss: 0.1162237\n","EarlyStopping counter: 15 out of 20\n","Epoch: 43, Train loss: 0.02187, Valid loss: 0.1162416\n","EarlyStopping counter: 16 out of 20\n","Epoch: 44, Train loss: 0.02191, Valid loss: 0.1161840\n","EarlyStopping counter: 17 out of 20\n","Epoch: 45, Train loss: 0.02171, Valid loss: 0.1162047\n","EarlyStopping counter: 18 out of 20\n","Epoch: 46, Train loss: 0.02167, Valid loss: 0.1160804\n","EarlyStopping counter: 19 out of 20\n","Epoch: 47, Train loss: 0.02153, Valid loss: 0.1160228\n","EarlyStopping counter: 20 out of 20\n","Early stopping at epoch:  47\n","Test loss: 0.07161484099924564\n","Test MSE: 48.83 MSE\n","Test MAPE: 0.03780648798735175\n","Train loss: 0.07150985486805439\n","Train MSE: 48.70 MSE\n","Train MAPE: 0.03777007125369946\n","Valid loss: 0.07134470157325268\n","Valid MSE: 48.56 MSE\n","Valid MAPE: 0.037732349568802295\n","HERE\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["<style>\n","    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n","    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n","    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n","    </style>\n","<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Epoch</td><td>▁▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>average_train_loss</td><td>██▇▇▇▆▆▅▅▄▄▃▃▃▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>average_valid_loss</td><td>███████▇▇▆▅▄▄▃▃▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>mape_test_score</td><td>▁</td></tr><tr><td>mape_train_score</td><td>▁</td></tr><tr><td>mse_test_score</td><td>▁</td></tr><tr><td>mse_train_score</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Epoch</td><td>47</td></tr><tr><td>average_train_loss</td><td>0.02153</td></tr><tr><td>average_valid_loss</td><td>0.11602</td></tr><tr><td>mape_test_score</td><td>0.03781</td></tr><tr><td>mape_train_score</td><td>0.03777</td></tr><tr><td>mse_test_score</td><td>48.82911</td></tr><tr><td>mse_train_score</td><td>48.69807</td></tr></table><br/></div></div>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Synced <strong style=\"color:#cdcd00\">mild-sweep-27</strong>: <a href=\"https://wandb.ai/metu_datacraft/DSS/runs/aprik6hl\" target=\"_blank\">https://wandb.ai/metu_datacraft/DSS/runs/aprik6hl</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Find logs at: <code>./wandb/run-20221231_211349-aprik6hl/logs</code>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 9x68x99o with config:\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 42\n","\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_size: 8\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_layers: 1\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tseq_len: 8\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Tracking run with wandb version 0.13.7"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Run data is saved locally in <code>/content/wandb/run-20221231_211359-9x68x99o</code>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Syncing run <strong><a href=\"https://wandb.ai/metu_datacraft/DSS/runs/9x68x99o\" target=\"_blank\">curious-sweep-28</a></strong> to <a href=\"https://wandb.ai/metu_datacraft/DSS\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/metu_datacraft/DSS/sweeps/owq2i7p2\" target=\"_blank\">https://wandb.ai/metu_datacraft/DSS/sweeps/owq2i7p2</a>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Epoch: 0, Train loss: 1.04866, Valid loss: 1.2095445\n","Epoch: 1, Train loss: 0.94941, Valid loss: 1.1659660\n","Epoch: 2, Train loss: 0.82507, Valid loss: 1.0900398\n","Epoch: 3, Train loss: 0.75436, Valid loss: 0.9976888\n","Epoch: 4, Train loss: 0.59405, Valid loss: 0.8472529\n","Epoch: 5, Train loss: 0.50003, Valid loss: 0.7323056\n","Epoch: 6, Train loss: 0.39250, Valid loss: 0.5976945\n","Epoch: 7, Train loss: 0.30132, Valid loss: 0.4674412\n","Epoch: 8, Train loss: 0.19869, Valid loss: 0.3591417\n","Epoch: 9, Train loss: 0.17924, Valid loss: 0.2976911\n","Epoch: 10, Train loss: 0.13213, Valid loss: 0.2539073\n","Epoch: 11, Train loss: 0.11944, Valid loss: 0.2320869\n","Epoch: 12, Train loss: 0.11705, Valid loss: 0.2144900\n","Epoch: 13, Train loss: 0.10400, Valid loss: 0.2006203\n","Epoch: 14, Train loss: 0.10480, Valid loss: 0.1837989\n","Epoch: 15, Train loss: 0.08411, Valid loss: 0.1651007\n","Epoch: 16, Train loss: 0.07361, Valid loss: 0.1525893\n","Epoch: 17, Train loss: 0.07289, Valid loss: 0.1416921\n","Epoch: 18, Train loss: 0.06061, Valid loss: 0.1269363\n","Epoch: 19, Train loss: 0.05914, Valid loss: 0.1160125\n","Epoch: 20, Train loss: 0.04823, Valid loss: 0.1111192\n","Epoch: 21, Train loss: 0.05155, Valid loss: 0.1026365\n","Epoch: 22, Train loss: 0.03701, Valid loss: 0.0930004\n","Epoch: 23, Train loss: 0.03582, Valid loss: 0.0858327\n","Epoch: 24, Train loss: 0.02869, Valid loss: 0.0790714\n","Epoch: 25, Train loss: 0.03265, Valid loss: 0.0804596\n","EarlyStopping counter: 1 out of 20\n","Epoch: 26, Train loss: 0.02584, Valid loss: 0.0807562\n","EarlyStopping counter: 2 out of 20\n","Epoch: 27, Train loss: 0.02228, Valid loss: 0.0786902\n","Epoch: 28, Train loss: 0.02259, Valid loss: 0.0719885\n","Epoch: 29, Train loss: 0.01854, Valid loss: 0.0723596\n","EarlyStopping counter: 1 out of 20\n","Epoch: 30, Train loss: 0.01871, Valid loss: 0.0672582\n","Epoch: 31, Train loss: 0.01823, Valid loss: 0.0665653\n","Epoch: 32, Train loss: 0.01627, Valid loss: 0.0715673\n","EarlyStopping counter: 1 out of 20\n","Epoch: 33, Train loss: 0.01594, Valid loss: 0.0689944\n","EarlyStopping counter: 2 out of 20\n","Epoch: 34, Train loss: 0.01879, Valid loss: 0.0672719\n","EarlyStopping counter: 3 out of 20\n","Epoch: 35, Train loss: 0.01670, Valid loss: 0.0679137\n","EarlyStopping counter: 4 out of 20\n","Epoch: 36, Train loss: 0.01649, Valid loss: 0.0665867\n","EarlyStopping counter: 5 out of 20\n","Epoch: 37, Train loss: 0.01802, Valid loss: 0.0704666\n","EarlyStopping counter: 6 out of 20\n","Epoch: 38, Train loss: 0.01559, Valid loss: 0.0628870\n","Epoch: 39, Train loss: 0.01446, Valid loss: 0.0638006\n","EarlyStopping counter: 1 out of 20\n","Epoch: 40, Train loss: 0.01538, Valid loss: 0.0629940\n","EarlyStopping counter: 2 out of 20\n","Epoch: 41, Train loss: 0.01464, Valid loss: 0.0654984\n","EarlyStopping counter: 3 out of 20\n","Epoch: 42, Train loss: 0.01570, Valid loss: 0.0618872\n","Epoch: 43, Train loss: 0.01388, Valid loss: 0.0578917\n","Epoch: 44, Train loss: 0.01439, Valid loss: 0.0614688\n","EarlyStopping counter: 1 out of 20\n","Epoch: 45, Train loss: 0.01359, Valid loss: 0.0596592\n","EarlyStopping counter: 2 out of 20\n","Epoch: 46, Train loss: 0.01539, Valid loss: 0.0631903\n","EarlyStopping counter: 3 out of 20\n","Epoch: 47, Train loss: 0.01415, Valid loss: 0.0590991\n","EarlyStopping counter: 4 out of 20\n","Epoch: 48, Train loss: 0.01330, Valid loss: 0.0575750\n","Epoch: 49, Train loss: 0.01615, Valid loss: 0.0590038\n","EarlyStopping counter: 1 out of 20\n","Epoch: 50, Train loss: 0.01334, Valid loss: 0.0576508\n","EarlyStopping counter: 2 out of 20\n","Epoch: 51, Train loss: 0.01236, Valid loss: 0.0594958\n","EarlyStopping counter: 3 out of 20\n","Epoch: 52, Train loss: 0.01212, Valid loss: 0.0575581\n","EarlyStopping counter: 4 out of 20\n","Epoch: 53, Train loss: 0.01382, Valid loss: 0.0578745\n","EarlyStopping counter: 5 out of 20\n","Epoch: 54, Train loss: 0.01576, Valid loss: 0.0579086\n","EarlyStopping counter: 6 out of 20\n","Epoch: 55, Train loss: 0.01469, Valid loss: 0.0531053\n","Epoch: 56, Train loss: 0.01243, Valid loss: 0.0491420\n","Epoch: 57, Train loss: 0.01241, Valid loss: 0.0541553\n","EarlyStopping counter: 1 out of 20\n","Epoch: 58, Train loss: 0.01309, Valid loss: 0.0531847\n","EarlyStopping counter: 2 out of 20\n","Epoch: 59, Train loss: 0.01136, Valid loss: 0.0530057\n","EarlyStopping counter: 3 out of 20\n","Epoch: 60, Train loss: 0.01199, Valid loss: 0.0513327\n","EarlyStopping counter: 4 out of 20\n","Epoch: 61, Train loss: 0.01303, Valid loss: 0.0546975\n","EarlyStopping counter: 5 out of 20\n","Epoch: 62, Train loss: 0.01169, Valid loss: 0.0557724\n","EarlyStopping counter: 6 out of 20\n","Epoch: 63, Train loss: 0.01170, Valid loss: 0.0529572\n","EarlyStopping counter: 7 out of 20\n","Epoch: 64, Train loss: 0.01220, Valid loss: 0.0543043\n","EarlyStopping counter: 8 out of 20\n","Epoch: 65, Train loss: 0.01195, Valid loss: 0.0496324\n","EarlyStopping counter: 9 out of 20\n","Epoch: 66, Train loss: 0.01183, Valid loss: 0.0521701\n","EarlyStopping counter: 10 out of 20\n","Epoch: 67, Train loss: 0.01282, Valid loss: 0.0482345\n","Epoch: 68, Train loss: 0.01119, Valid loss: 0.0476450\n","Epoch: 69, Train loss: 0.01548, Valid loss: 0.0489342\n","EarlyStopping counter: 1 out of 20\n","Epoch: 70, Train loss: 0.01056, Valid loss: 0.0449736\n","Epoch: 71, Train loss: 0.01083, Valid loss: 0.0472015\n","EarlyStopping counter: 1 out of 20\n","Epoch: 72, Train loss: 0.01189, Valid loss: 0.0480525\n","EarlyStopping counter: 2 out of 20\n","Epoch: 73, Train loss: 0.01138, Valid loss: 0.0453786\n","EarlyStopping counter: 3 out of 20\n","Epoch: 74, Train loss: 0.01338, Valid loss: 0.0513811\n","EarlyStopping counter: 4 out of 20\n","Epoch: 75, Train loss: 0.01191, Valid loss: 0.0502114\n","EarlyStopping counter: 5 out of 20\n","Epoch: 76, Train loss: 0.01024, Valid loss: 0.0437484\n","Epoch: 77, Train loss: 0.01106, Valid loss: 0.0457506\n","EarlyStopping counter: 1 out of 20\n","Epoch: 78, Train loss: 0.01155, Valid loss: 0.0449539\n","EarlyStopping counter: 2 out of 20\n","Epoch: 79, Train loss: 0.01116, Valid loss: 0.0480779\n","EarlyStopping counter: 3 out of 20\n","Epoch: 80, Train loss: 0.01076, Valid loss: 0.0440782\n","EarlyStopping counter: 4 out of 20\n","Epoch: 81, Train loss: 0.00979, Valid loss: 0.0440679\n","EarlyStopping counter: 5 out of 20\n","Epoch: 82, Train loss: 0.01108, Valid loss: 0.0433699\n","Epoch: 83, Train loss: 0.01020, Valid loss: 0.0420324\n","Epoch: 84, Train loss: 0.00961, Valid loss: 0.0434992\n","EarlyStopping counter: 1 out of 20\n","Epoch: 85, Train loss: 0.01028, Valid loss: 0.0430028\n","EarlyStopping counter: 2 out of 20\n","Epoch: 86, Train loss: 0.00947, Valid loss: 0.0444588\n","EarlyStopping counter: 3 out of 20\n","Epoch: 87, Train loss: 0.01026, Valid loss: 0.0408197\n","Epoch: 88, Train loss: 0.00980, Valid loss: 0.0461590\n","EarlyStopping counter: 1 out of 20\n","Epoch: 89, Train loss: 0.01110, Valid loss: 0.0421307\n","EarlyStopping counter: 2 out of 20\n","Epoch: 90, Train loss: 0.01035, Valid loss: 0.0402688\n","Epoch: 91, Train loss: 0.01057, Valid loss: 0.0437978\n","EarlyStopping counter: 1 out of 20\n","Epoch: 92, Train loss: 0.00918, Valid loss: 0.0401764\n","EarlyStopping counter: 2 out of 20\n","Epoch: 93, Train loss: 0.00895, Valid loss: 0.0397596\n","Epoch: 94, Train loss: 0.00935, Valid loss: 0.0414236\n","EarlyStopping counter: 1 out of 20\n","Epoch: 95, Train loss: 0.00894, Valid loss: 0.0401017\n","EarlyStopping counter: 2 out of 20\n","Epoch: 96, Train loss: 0.00931, Valid loss: 0.0405734\n","EarlyStopping counter: 3 out of 20\n","Epoch: 97, Train loss: 0.00906, Valid loss: 0.0415486\n","EarlyStopping counter: 4 out of 20\n","Epoch: 98, Train loss: 0.00890, Valid loss: 0.0393688\n","Epoch: 99, Train loss: 0.00938, Valid loss: 0.0395742\n","EarlyStopping counter: 1 out of 20\n","Epoch: 100, Train loss: 0.00892, Valid loss: 0.0399863\n","EarlyStopping counter: 2 out of 20\n","Epoch: 101, Train loss: 0.00922, Valid loss: 0.0384796\n","Epoch: 102, Train loss: 0.00878, Valid loss: 0.0382245\n","Epoch: 103, Train loss: 0.00972, Valid loss: 0.0377058\n","Epoch: 104, Train loss: 0.00917, Valid loss: 0.0368175\n","Epoch: 105, Train loss: 0.00856, Valid loss: 0.0375277\n","EarlyStopping counter: 1 out of 20\n","Epoch: 106, Train loss: 0.00848, Valid loss: 0.0357019\n","Epoch: 107, Train loss: 0.00845, Valid loss: 0.0380634\n","EarlyStopping counter: 1 out of 20\n","Epoch: 108, Train loss: 0.00838, Valid loss: 0.0368087\n","EarlyStopping counter: 2 out of 20\n","Epoch: 109, Train loss: 0.00820, Valid loss: 0.0366358\n","EarlyStopping counter: 3 out of 20\n","Epoch: 110, Train loss: 0.00849, Valid loss: 0.0348161\n","Epoch: 111, Train loss: 0.00831, Valid loss: 0.0347275\n","EarlyStopping counter: 1 out of 20\n","Epoch: 112, Train loss: 0.01057, Valid loss: 0.0356263\n","EarlyStopping counter: 2 out of 20\n","Epoch: 113, Train loss: 0.00885, Valid loss: 0.0360902\n","EarlyStopping counter: 3 out of 20\n","Epoch: 114, Train loss: 0.00909, Valid loss: 0.0344834\n","Epoch: 115, Train loss: 0.00891, Valid loss: 0.0368502\n","EarlyStopping counter: 1 out of 20\n","Epoch: 116, Train loss: 0.00796, Valid loss: 0.0325782\n","Epoch: 117, Train loss: 0.00790, Valid loss: 0.0346943\n","EarlyStopping counter: 1 out of 20\n","Epoch: 118, Train loss: 0.00766, Valid loss: 0.0340555\n","EarlyStopping counter: 2 out of 20\n","Epoch: 119, Train loss: 0.00767, Valid loss: 0.0334258\n","EarlyStopping counter: 3 out of 20\n","Epoch: 120, Train loss: 0.00773, Valid loss: 0.0338447\n","EarlyStopping counter: 4 out of 20\n","Epoch: 121, Train loss: 0.00817, Valid loss: 0.0329393\n","EarlyStopping counter: 5 out of 20\n","Epoch: 122, Train loss: 0.00835, Valid loss: 0.0352023\n","EarlyStopping counter: 6 out of 20\n","Epoch: 123, Train loss: 0.00787, Valid loss: 0.0333675\n","EarlyStopping counter: 7 out of 20\n","Epoch: 124, Train loss: 0.00895, Valid loss: 0.0318208\n","Epoch: 125, Train loss: 0.00806, Valid loss: 0.0336822\n","EarlyStopping counter: 1 out of 20\n","Epoch: 126, Train loss: 0.00747, Valid loss: 0.0335937\n","EarlyStopping counter: 2 out of 20\n","Epoch: 127, Train loss: 0.00758, Valid loss: 0.0322098\n","EarlyStopping counter: 3 out of 20\n","Epoch: 128, Train loss: 0.00712, Valid loss: 0.0314189\n","Epoch: 129, Train loss: 0.00731, Valid loss: 0.0308741\n","Epoch: 130, Train loss: 0.00717, Valid loss: 0.0310735\n","EarlyStopping counter: 1 out of 20\n","Epoch: 131, Train loss: 0.00722, Valid loss: 0.0311721\n","EarlyStopping counter: 2 out of 20\n","Epoch: 132, Train loss: 0.00793, Valid loss: 0.0320182\n","EarlyStopping counter: 3 out of 20\n","Epoch: 133, Train loss: 0.00772, Valid loss: 0.0315549\n","EarlyStopping counter: 4 out of 20\n","Epoch: 134, Train loss: 0.00737, Valid loss: 0.0301130\n","Epoch: 135, Train loss: 0.00875, Valid loss: 0.0305464\n","EarlyStopping counter: 1 out of 20\n","Epoch: 136, Train loss: 0.00806, Valid loss: 0.0294145\n","Epoch: 137, Train loss: 0.00674, Valid loss: 0.0320502\n","EarlyStopping counter: 1 out of 20\n","Epoch: 138, Train loss: 0.00690, Valid loss: 0.0302350\n","EarlyStopping counter: 2 out of 20\n","Epoch: 139, Train loss: 0.00696, Valid loss: 0.0304218\n","EarlyStopping counter: 3 out of 20\n","Epoch: 140, Train loss: 0.00680, Valid loss: 0.0293874\n","EarlyStopping counter: 4 out of 20\n","Epoch: 141, Train loss: 0.00740, Valid loss: 0.0303554\n","EarlyStopping counter: 5 out of 20\n","Epoch: 142, Train loss: 0.00696, Valid loss: 0.0296229\n","EarlyStopping counter: 6 out of 20\n","Epoch: 143, Train loss: 0.00699, Valid loss: 0.0288591\n","Epoch: 144, Train loss: 0.00805, Valid loss: 0.0282173\n","Epoch: 145, Train loss: 0.00710, Valid loss: 0.0267337\n","Epoch: 146, Train loss: 0.00750, Valid loss: 0.0290352\n","EarlyStopping counter: 1 out of 20\n","Epoch: 147, Train loss: 0.00697, Valid loss: 0.0277800\n","EarlyStopping counter: 2 out of 20\n","Epoch: 148, Train loss: 0.00651, Valid loss: 0.0280514\n","EarlyStopping counter: 3 out of 20\n","Epoch: 149, Train loss: 0.00708, Valid loss: 0.0274741\n","EarlyStopping counter: 4 out of 20\n","Epoch: 150, Train loss: 0.00650, Valid loss: 0.0273838\n","EarlyStopping counter: 5 out of 20\n","Epoch: 151, Train loss: 0.00649, Valid loss: 0.0274368\n","EarlyStopping counter: 6 out of 20\n","Epoch: 152, Train loss: 0.00672, Valid loss: 0.0263346\n","Epoch: 153, Train loss: 0.00663, Valid loss: 0.0277551\n","EarlyStopping counter: 1 out of 20\n","Epoch: 154, Train loss: 0.00625, Valid loss: 0.0268716\n","EarlyStopping counter: 2 out of 20\n","Epoch: 155, Train loss: 0.00685, Valid loss: 0.0271148\n","EarlyStopping counter: 3 out of 20\n","Epoch: 156, Train loss: 0.00668, Valid loss: 0.0259001\n","Epoch: 157, Train loss: 0.00624, Valid loss: 0.0261114\n","EarlyStopping counter: 1 out of 20\n","Epoch: 158, Train loss: 0.00640, Valid loss: 0.0266123\n","EarlyStopping counter: 2 out of 20\n","Epoch: 159, Train loss: 0.00631, Valid loss: 0.0268044\n","EarlyStopping counter: 3 out of 20\n","Epoch: 160, Train loss: 0.00677, Valid loss: 0.0259567\n","EarlyStopping counter: 4 out of 20\n","Epoch: 161, Train loss: 0.00628, Valid loss: 0.0255990\n","Epoch: 162, Train loss: 0.00660, Valid loss: 0.0262610\n","EarlyStopping counter: 1 out of 20\n","Epoch: 163, Train loss: 0.00619, Valid loss: 0.0271036\n","EarlyStopping counter: 2 out of 20\n","Epoch: 164, Train loss: 0.00631, Valid loss: 0.0253912\n","Epoch: 165, Train loss: 0.00615, Valid loss: 0.0266642\n","EarlyStopping counter: 1 out of 20\n","Epoch: 166, Train loss: 0.00625, Valid loss: 0.0251667\n","Epoch: 167, Train loss: 0.00594, Valid loss: 0.0250582\n","Epoch: 168, Train loss: 0.00611, Valid loss: 0.0251104\n","EarlyStopping counter: 1 out of 20\n","Epoch: 169, Train loss: 0.00632, Valid loss: 0.0244280\n","Epoch: 170, Train loss: 0.00588, Valid loss: 0.0250475\n","EarlyStopping counter: 1 out of 20\n","Epoch: 171, Train loss: 0.00595, Valid loss: 0.0247494\n","EarlyStopping counter: 2 out of 20\n","Epoch: 172, Train loss: 0.00644, Valid loss: 0.0253023\n","EarlyStopping counter: 3 out of 20\n","Epoch: 173, Train loss: 0.00584, Valid loss: 0.0255169\n","EarlyStopping counter: 4 out of 20\n","Epoch: 174, Train loss: 0.00570, Valid loss: 0.0251920\n","EarlyStopping counter: 5 out of 20\n","Epoch: 175, Train loss: 0.00585, Valid loss: 0.0240451\n","Epoch: 176, Train loss: 0.00570, Valid loss: 0.0244389\n","EarlyStopping counter: 1 out of 20\n","Epoch: 177, Train loss: 0.00577, Valid loss: 0.0241597\n","EarlyStopping counter: 2 out of 20\n","Epoch: 178, Train loss: 0.00695, Valid loss: 0.0234678\n","Epoch: 179, Train loss: 0.00624, Valid loss: 0.0233158\n","Epoch: 180, Train loss: 0.00733, Valid loss: 0.0236272\n","EarlyStopping counter: 1 out of 20\n","Epoch: 181, Train loss: 0.00695, Valid loss: 0.0248216\n","EarlyStopping counter: 2 out of 20\n","Epoch: 182, Train loss: 0.00653, Valid loss: 0.0235470\n","EarlyStopping counter: 3 out of 20\n","Epoch: 183, Train loss: 0.00551, Valid loss: 0.0238281\n","EarlyStopping counter: 4 out of 20\n","Epoch: 184, Train loss: 0.00566, Valid loss: 0.0235240\n","EarlyStopping counter: 5 out of 20\n","Epoch: 185, Train loss: 0.00541, Valid loss: 0.0228934\n","Epoch: 186, Train loss: 0.00552, Valid loss: 0.0233668\n","EarlyStopping counter: 1 out of 20\n","Epoch: 187, Train loss: 0.00556, Valid loss: 0.0235348\n","EarlyStopping counter: 2 out of 20\n","Epoch: 188, Train loss: 0.00583, Valid loss: 0.0235568\n","EarlyStopping counter: 3 out of 20\n","Epoch: 189, Train loss: 0.00650, Valid loss: 0.0229653\n","EarlyStopping counter: 4 out of 20\n","Epoch: 190, Train loss: 0.00705, Valid loss: 0.0229688\n","EarlyStopping counter: 5 out of 20\n","Epoch: 191, Train loss: 0.00585, Valid loss: 0.0225629\n","Epoch: 192, Train loss: 0.00544, Valid loss: 0.0227185\n","EarlyStopping counter: 1 out of 20\n","Epoch: 193, Train loss: 0.00585, Valid loss: 0.0228270\n","EarlyStopping counter: 2 out of 20\n","Epoch: 194, Train loss: 0.00579, Valid loss: 0.0225147\n","EarlyStopping counter: 3 out of 20\n","Epoch: 195, Train loss: 0.00555, Valid loss: 0.0228589\n","EarlyStopping counter: 4 out of 20\n","Epoch: 196, Train loss: 0.00646, Valid loss: 0.0235000\n","EarlyStopping counter: 5 out of 20\n","Epoch: 197, Train loss: 0.00559, Valid loss: 0.0217731\n","Epoch: 198, Train loss: 0.00578, Valid loss: 0.0229759\n","EarlyStopping counter: 1 out of 20\n","Epoch: 199, Train loss: 0.00575, Valid loss: 0.0228159\n","EarlyStopping counter: 2 out of 20\n","Epoch: 200, Train loss: 0.00591, Valid loss: 0.0229734\n","EarlyStopping counter: 3 out of 20\n","Epoch: 201, Train loss: 0.00653, Valid loss: 0.0228815\n","EarlyStopping counter: 4 out of 20\n","Epoch: 202, Train loss: 0.00561, Valid loss: 0.0230163\n","EarlyStopping counter: 5 out of 20\n","Epoch: 203, Train loss: 0.00565, Valid loss: 0.0224187\n","EarlyStopping counter: 6 out of 20\n","Epoch: 204, Train loss: 0.00612, Valid loss: 0.0216584\n","Epoch: 205, Train loss: 0.00532, Valid loss: 0.0223233\n","EarlyStopping counter: 1 out of 20\n","Epoch: 206, Train loss: 0.00553, Valid loss: 0.0215888\n","EarlyStopping counter: 2 out of 20\n","Epoch: 207, Train loss: 0.00525, Valid loss: 0.0218866\n","EarlyStopping counter: 3 out of 20\n","Epoch: 208, Train loss: 0.00519, Valid loss: 0.0214944\n","Epoch: 209, Train loss: 0.00551, Valid loss: 0.0217935\n","EarlyStopping counter: 1 out of 20\n","Epoch: 210, Train loss: 0.00551, Valid loss: 0.0224456\n","EarlyStopping counter: 2 out of 20\n","Epoch: 211, Train loss: 0.00541, Valid loss: 0.0215651\n","EarlyStopping counter: 3 out of 20\n","Epoch: 212, Train loss: 0.00527, Valid loss: 0.0213253\n","Epoch: 213, Train loss: 0.00693, Valid loss: 0.0208140\n","Epoch: 214, Train loss: 0.00654, Valid loss: 0.0205905\n","Epoch: 215, Train loss: 0.00609, Valid loss: 0.0208721\n","EarlyStopping counter: 1 out of 20\n","Epoch: 216, Train loss: 0.00535, Valid loss: 0.0206454\n","EarlyStopping counter: 2 out of 20\n","Epoch: 217, Train loss: 0.00500, Valid loss: 0.0210162\n","EarlyStopping counter: 3 out of 20\n","Epoch: 218, Train loss: 0.00521, Valid loss: 0.0206001\n","EarlyStopping counter: 4 out of 20\n","Epoch: 219, Train loss: 0.00504, Valid loss: 0.0210105\n","EarlyStopping counter: 5 out of 20\n","Epoch: 220, Train loss: 0.00498, Valid loss: 0.0208820\n","EarlyStopping counter: 6 out of 20\n","Epoch: 221, Train loss: 0.00500, Valid loss: 0.0208310\n","EarlyStopping counter: 7 out of 20\n","Epoch: 222, Train loss: 0.00554, Valid loss: 0.0208878\n","EarlyStopping counter: 8 out of 20\n","Epoch: 223, Train loss: 0.00529, Valid loss: 0.0208430\n","EarlyStopping counter: 9 out of 20\n","Epoch: 224, Train loss: 0.00495, Valid loss: 0.0206509\n","EarlyStopping counter: 10 out of 20\n","Epoch: 225, Train loss: 0.00539, Valid loss: 0.0210143\n","EarlyStopping counter: 11 out of 20\n","Epoch: 226, Train loss: 0.00506, Valid loss: 0.0211915\n","EarlyStopping counter: 12 out of 20\n","Epoch: 227, Train loss: 0.00489, Valid loss: 0.0213746\n","EarlyStopping counter: 13 out of 20\n","Epoch: 228, Train loss: 0.00511, Valid loss: 0.0211023\n","EarlyStopping counter: 14 out of 20\n","Epoch: 229, Train loss: 0.00489, Valid loss: 0.0209564\n","EarlyStopping counter: 15 out of 20\n","Epoch: 230, Train loss: 0.00481, Valid loss: 0.0209802\n","EarlyStopping counter: 16 out of 20\n","Epoch: 231, Train loss: 0.00633, Valid loss: 0.0207924\n","EarlyStopping counter: 17 out of 20\n","Epoch: 232, Train loss: 0.00476, Valid loss: 0.0206381\n","EarlyStopping counter: 18 out of 20\n","Epoch: 233, Train loss: 0.00525, Valid loss: 0.0206001\n","EarlyStopping counter: 19 out of 20\n","Epoch: 234, Train loss: 0.00569, Valid loss: 0.0209643\n","EarlyStopping counter: 20 out of 20\n","Early stopping at epoch:  234\n","Test loss: 0.01436386164277792\n","Test MSE: 8.37 MSE\n","Test MAPE: 0.015495197237126498\n","Train loss: 0.014493132010102272\n","Train MSE: 8.40 MSE\n","Train MAPE: 0.015425836030240787\n","Valid loss: 0.014422986656427383\n","Valid MSE: 8.39 MSE\n","Valid MAPE: 0.015457994586804632\n","HERE\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Ctrl + C detected. Stopping sweep.\n"]}],"source":["def train(config=None):\n","  with wandb.init(config=config):\n","    config = wandb.config\n","\n","    data['Date'] = pd.to_datetime(data.Date)\n","\n","    SeqLen = config.seq_len\n","\n","    #split dataset\n","    train, valid, test = split(data[[\"Price\",\"Open\"]],SeqLen)\n","\n","    #scale the colums and values\n","    scaler = StandardScaler()\n","    train_scaled = scaler.fit_transform(train) #fit the scaler by using train dataset\n","    test_scaled = scaler.transform(test) #scale the test dataset\n","    valid_scaled = scaler.transform(valid) #scale the validation daatset\n","\n","    train_data = pd.DataFrame(train_scaled, columns = ['Price','Open'])\n","    test_data = pd.DataFrame(test_scaled, columns = ['Price','Open'])\n","    valid_data = pd.DataFrame(valid_scaled, columns = ['Price','Open'])\n","\n","    #get sequences of the dataset\n","    train_dataset = SequenceDataset(\n","        train_data,\n","        target=\"Price\",\n","        features=[\"Open\"],\n","        sequence_length=SeqLen\n","    )\n","\n","\n","    test_dataset = SequenceDataset(\n","        test_data,\n","        target=\"Price\",\n","        features=[\"Open\"],\n","        sequence_length=SeqLen\n","    )\n","\n","    valid_dataset = SequenceDataset(\n","        valid_data,\n","        target=\"Price\",\n","        features=[\"Open\"],\n","        sequence_length=SeqLen\n","    )\n","\n","    #create the dataloader for the dataset to create batches\n","    trainloader = DataLoader(train_dataset, batch_size=config.batch_size, shuffle=True)\n","    testloader = DataLoader(test_dataset,batch_size=config.batch_size,shuffle=False)\n","    validloader = DataLoader(valid_dataset,batch_size=config.batch_size,shuffle=False)\n","\n","    #call model\n","    model = LSTM(input_dim=input_dim, hidden_dim=config.hidden_size, num_layers=config.num_layers,output_dim=output_dim).to(DEVICE)\n","\n","    criterion = torch.nn.MSELoss()    # define criterion for loss: mean-squared error \n","    optimizer = torch.optim.AdamW(model.parameters(), lr=1e-3) #define optimizer\n","\n","    #apply learning rate scheduler\n","    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=10, threshold=0.0001, threshold_mode='abs')\n","\n","    #use early stopping for tuning\n","    early_stopping = EarlyStopping(patience=20, delta=0.0001, verbose=False)\n","\n","    #keep steps to calculate average loss values\n","    trainSteps = len(train_dataset) //config.batch_size\n","    testSteps = len(test_dataset)//config.batch_size\n","    validSteps = len(valid_dataset)//config.batch_size\n","    count=0\n","    for epoch in range(n_epochs):\n","      model.train()\n","      train_loss = 0\n","      \n","      for X, y in trainloader:\n","          X=X.to(DEVICE)\n","          y=y.to(DEVICE)\n","          output = model(X)\n","          output=torch.reshape(output, (-1,))\n","          loss = criterion(output, y) #calculate the loss\n","          optimizer.zero_grad()\n","          loss.backward()\n","          optimizer.step()\n","          train_loss += loss.item() #calculate the total loss\n","            \n","      #check the validation loss to measure the training performance\n","      valid_loss=0\n","      model.eval()\n","      with torch.no_grad():\n","          for X, y in validloader:\n","              X=X.to(DEVICE)\n","              y=y.to(DEVICE)\n","              predict = model(X)\n","              predict=torch.reshape(predict, (-1,))\n","              valid_loss += criterion(predict, y).item()\n","              \n","      #calculate the loss values of train and validation        \n","      avg_train_loss = train_loss / trainSteps  \n","      avg_valid_loss = valid_loss / validSteps\n","\n","      print(\"Epoch: %d, Train loss: %1.5f, Valid loss: %1.7f\" % (epoch, avg_train_loss,avg_valid_loss))\n","\n","      wandb.log({\"Epoch\":epoch, \"average_train_loss\": avg_train_loss,\"average_valid_loss\":avg_valid_loss})\n","      \n","      #step the learning rate scheduler \n","      scheduler.step(avg_valid_loss)\n","\n","      early_stopping(avg_valid_loss, model)\n","\n","            \n","      if early_stopping.early_stop:\n","          print(\"Early stopping at epoch: \", epoch)\n","          break\n","\n","\n","    mape_test,mse_test=evaluation(\"Test\",test_scaled,testSteps,model,testloader,criterion,scaler)\n","    mape_train,mse_train=evaluation(\"Train\",train_scaled,testSteps,model,trainloader,criterion,scaler)\n","    mape_valid,mse_valid=evaluation(\"Valid\",valid_scaled,testSteps,model,validloader,criterion,scaler)\n","\n","  \n","    #log the scores\n","    wandb.log({\"mse_test_score\": mse_test, \"mape_test_score\": mape_test,\"mse_train_score\":mse_train,\"mape_train_score\":mape_train})\n","\n","    #put if condition to save the model when the model performance reaches the business objective\n","    if mape_test < mape_test_score_goal: \n","      print(\"HERE\")\n","      torch.save(model.state_dict(), \"/content/gdrive/My Drive/Colab Notebooks/DataCraft_notebook/model{company}{number}.pth\".format(company=company,number=count))  #####LOCAL İCİN DÜZENLENECEK\n","      count+=1\n","\n","wandb.agent(sweep_id, train)"]}],"metadata":{"accelerator":"GPU","colab":{"machine_shape":"hm","provenance":[]},"gpuClass":"premium","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"86a96b225d1049458950f40b09179954":{"model_module":"@jupyter-widgets/controls","model_name":"VBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"VBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"VBoxView","box_style":"","children":["IPY_MODEL_e8f923af5fec463c8d146659e9405b09","IPY_MODEL_82e0951974fa4b41889bd9e6ceafb5f4"],"layout":"IPY_MODEL_d6d710abdb05471b8f567ec3fed6af61"}},"e8f923af5fec463c8d146659e9405b09":{"model_module":"@jupyter-widgets/controls","model_name":"LabelModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"LabelModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"LabelView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3f2ba4404eb8459a90839482b918ace7","placeholder":"​","style":"IPY_MODEL_aba446c5a4ab4203ac06d51bf109c483","value":"0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\r"}},"82e0951974fa4b41889bd9e6ceafb5f4":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_92126f75e1934a0faf46d54fdd0a95b7","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_055348133f854e0d8b1ab4d59cbbf608","value":1}},"d6d710abdb05471b8f567ec3fed6af61":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3f2ba4404eb8459a90839482b918ace7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"aba446c5a4ab4203ac06d51bf109c483":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"92126f75e1934a0faf46d54fdd0a95b7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"055348133f854e0d8b1ab4d59cbbf608":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}}}}},"nbformat":4,"nbformat_minor":0}